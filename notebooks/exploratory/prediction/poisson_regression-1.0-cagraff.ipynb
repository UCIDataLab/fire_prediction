{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Regression Testing (v1.0)\n",
    "\n",
    "Casey A Graff\n",
    "\n",
    "September 7th, 2017\n",
    "\n",
    "Developing and initial exploration of results from poisson regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REP_DIR = \"/home/cagraff/Documents/dev/fire_prediction/\"\n",
    "SRC_DIR = REP_DIR + 'src/'\n",
    "DATA_DIR = REP_DIR + 'data/'\n",
    "\n",
    "# Load system-wide packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import datetime as dt\n",
    "plt.rcParams['figure.figsize'] = [15,7]\n",
    "%matplotlib inline\n",
    "\n",
    "# Load project packages\n",
    "os.chdir(SRC_DIR)\n",
    "from features.loaders import load_integrated_df\n",
    "import models.poisson_regression as pr\n",
    "import models.linear_regression as lr\n",
    "import models.evaluation as ev\n",
    "from models import metrics\n",
    "from helper import date_util as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(SRC_DIR+'features')\n",
    "int_5km_10days_14_df = load_integrated_df(os.path.join(DATA_DIR, 'interim/integrated/fire_weather/fire_weather_integrated_gfs_modis_5km_10days_1400_alaska_2007-2016.pkl'))\n",
    "int_5km_10days_14_4rain_df = load_integrated_df(os.path.join(DATA_DIR, 'interim/integrated/fire_weather/fire_weather_integrated_gfs_modis_5km_10days_1400_rain-del-4_alaska_2007-2016.pkl'))\n",
    "int_5km_10days_14_8rain_df = load_integrated_df(os.path.join(DATA_DIR, 'interim/integrated/fire_weather/fire_weather_integrated_gfs_modis_5km_10days_1400_rain-del-8_alaska_2007-2016.pkl'))\n",
    "int_5km_10days_8_df = load_integrated_df(os.path.join(DATA_DIR, 'interim/integrated/fire_weather/fire_weather_integrated_gfs_modis_5km_10days_0800_alaska_2007-2016.pkl'))\n",
    "int_5km_10days_14_4raina_df = load_integrated_df(os.path.join(DATA_DIR, 'interim/integrated/fire_weather/fire_weather_integrated_gfs_modis_5km_10days_1400_rain-ahead-4_alaska_2007-2016.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_5km_10days_14_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(pr)\n",
    "reload(lr)\n",
    "reload(ev)\n",
    "\n",
    "def train(X, t_k_arr, leave_one_out=True, years=None):\n",
    "    # Standardize weather\n",
    "    for cov in ['temperature', 'humidity', 'wind', 'rain']:\n",
    "        X[cov] = (X[cov] - np.mean(X[cov])) / np.var(X[cov])\n",
    "\n",
    "    X = X.assign(year=map(lambda x: x.year, X.date_local))\n",
    "    \n",
    "    # Filter years\n",
    "    if years:\n",
    "        X = X[X.year.isin(years)]\n",
    "    \n",
    "    results_dict = defaultdict(list)\n",
    "    for t_k in t_k_arr:\n",
    "        print 'Starting t_k=%d' % t_k\n",
    "\n",
    "        # Filter out predicting before fire started\n",
    "        legit_series = pd.Series(index=X.index)\n",
    "        for clust in X.cluster_id.unique():\n",
    "            clust_df = X[X.cluster_id==clust]\n",
    "            legit_day = np.min(clust_df.date_local) + du.INC_ONE_DAY * (t_k+1)\n",
    "            legit_series[clust_df[clust_df.date_local>=legit_day].index]=1        \n",
    "\n",
    "        X_legit = X[legit_series==1]\n",
    "\n",
    "        X_t = pr.PoissonRegressionModel(t_k, []).add_autoregressive_col(X_legit, t_k+1)\n",
    "\n",
    "        results_dict['baseline'].append((X_t.num_det, X_t.num_det_prev))\n",
    "\n",
    "        prm = pr.PoissonRegressionModel(t_k=t_k, covariates=[])\n",
    "        if leave_one_out:\n",
    "            results, years = ev.cross_validation_years(prm, X_t)\n",
    "        else:\n",
    "            results, years = ev.leave_none_out(prm, X_t)\n",
    "        results_dict['auto'].append(np.concatenate(results, axis=1))\n",
    "\n",
    "        prm = pr.PoissonRegressionModel(t_k=t_k, covariates=['temperature', 'humidity'])\n",
    "        if leave_one_out:\n",
    "            results, years = ev.cross_validation_years(prm, X_t)\n",
    "        else:\n",
    "            results, years = ev.leave_none_out(prm, X_t)\n",
    "        results_dict['temp_humid'].append(np.concatenate(results, axis=1))\n",
    "\n",
    "        prm = pr.PoissonRegressionModel(t_k=t_k, covariates=['temperature', 'humidity', 'wind', 'rain'])\n",
    "        if leave_one_out:\n",
    "            results, years = ev.cross_validation_years(prm, X_t)\n",
    "        else:\n",
    "            results, years = ev.leave_none_out(prm, X_t)\n",
    "        results_dict['all'].append(np.concatenate(results, axis=1)) \n",
    "        \n",
    "        prm = pr.PoissonRegressionModel(t_k=t_k, covariates=['temperature', 'wind', 'rain'])\n",
    "        if leave_one_out:\n",
    "            results, years = ev.cross_validation_years(prm, X_t)\n",
    "        else:\n",
    "            results, years = ev.leave_none_out(prm, X_t)\n",
    "        results_dict['no_humid'].append(np.concatenate(results, axis=1)) \n",
    "        \n",
    "        prm = pr.PoissonRegressionModel(t_k=t_k, covariates=['temperature'])\n",
    "        if leave_one_out:\n",
    "            results, years = ev.cross_validation_years(prm, X_t)\n",
    "        else:\n",
    "            results, years = ev.leave_none_out(prm, X_t)\n",
    "        results_dict['temp'].append(np.concatenate(results, axis=1)) \n",
    "     \n",
    "        \"\"\"\n",
    "        lrm = lr.LinearRegressionModel(t_k=t_k, covariates=[])\n",
    "        if leave_one_out:\n",
    "            results, years = ev.cross_validation_years(lrm, X_t)\n",
    "        else:\n",
    "            results, years = ev.leave_none_out(prm, X_t)\n",
    "        results_dict['auto_linear'].append(np.concatenate(results, axis=1))\n",
    "        \n",
    "        lrm = lr.LinearRegressionModel(t_k=t_k, covariates=['temperature', 'humidity', 'wind', 'rain'])\n",
    "        if leave_one_out:\n",
    "            results, years = ev.cross_validation_years(lrm, X_t)\n",
    "        else:\n",
    "            results, years = ev.leave_none_out(prm, X_t)\n",
    "        results_dict['linear_all'].append(np.concatenate(results, axis=1))\n",
    "        \"\"\"\n",
    "    return results_dict\n",
    "        \n",
    "def plot_training(results, t_k_arr, metric=metrics.mean_absolute_error):\n",
    "    plt.plot(t_k_arr+1, map(lambda x: metric(*x), results['baseline']), \"kv--\", label=\"Baseline\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, map(lambda x: metric(*x), results['auto']), \"gs--\", label=\"Autoregression\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, map(lambda x: metric(*x), results['temp_humid']), \"r^--\", label=\"Temp/hum\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, map(lambda x: metric(*x), results['all']), \"bo--\", label=\"All weather\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, map(lambda x: metric(*x), results['no_humid']), \"co--\", label=\"All (except humid)\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, map(lambda x: metric(*x), results['temp']), \"yo--\", label=\"Temp Only\", linewidth=2)\n",
    "    #plt.plot(t_k_arr+1, map(lambda x: metric(*x), results['auto_linear']), \"cs--\", label='Linear Autoregression', linewidth=2)\n",
    "    #plt.plot(t_k_arr+1, map(lambda x: metric(*x), results['linear_all']), \"yo--\", label='Linear All', linewidth=2)\n",
    "\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlabel(\"Day of forecast (k)\")\n",
    "    plt.xticks(t_k_arr+1)\n",
    "    plt.ylabel(metric.__name__)\n",
    "    \n",
    "def print_summary(X, cov_list, t_k):\n",
    "    # Standardize weather\n",
    "    for cov in cov_list:\n",
    "        X[cov] = (X[cov] - np.mean(X[cov])) / np.var(X[cov])\n",
    "\n",
    "    X = X.assign(year=map(lambda x: x.year, X.date_local))\n",
    "    X_t = pr.PoissonRegressionModel(t_k, []).add_autoregressive_col(X, t_k+1)\n",
    "\n",
    "    prm = pr.PoissonRegressionModel(t_k=t_k, covariates=cov_list)\n",
    "    results, years = ev.cross_validation_years(prm, X_t)\n",
    "    print 'Mean Abs. Error: %f' % metrics.mean_absolute_error(*np.concatenate(results, axis=1))\n",
    "    print prm.fit_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Clusterings on Ten Year (out of sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "results = train(int_5km_10days_14_df.copy(), t_k_arr)\n",
    "plot_training(results, t_k_arr, metrics.mean_absolute_error)\n",
    "plt.show()\n",
    "plot_training(results, t_k_arr, metrics.root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "results = train(int_5km_10days_14_4rain_df.copy(), t_k_arr)\n",
    "plot_training(results, t_k_arr, metrics.mean_absolute_error)\n",
    "plt.show()\n",
    "plot_training(results, t_k_arr, metrics.root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "results = train(int_5km_10days_14_8rain_df.copy(), t_k_arr)\n",
    "plot_training(results, t_k_arr, metrics.mean_absolute_error)\n",
    "plt.show()\n",
    "plot_training(results, t_k_arr, metrics.root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "results = train(int_5km_10days_14_4raina_df.copy(), t_k_arr)\n",
    "plot_training(results, t_k_arr, metrics.mean_absolute_error)\n",
    "plt.show()\n",
    "plot_training(results, t_k_arr, metrics.root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Clusterings on Ten Year (in sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "results = train(int_5km_10days_14_df.copy(), t_k_arr, False)\n",
    "plot_training(results, t_k_arr, metrics.mean_absolute_error)\n",
    "plt.show()\n",
    "plot_training(results, t_k_arr, metrics.root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "results = train(int_5km_10days_14_4rain_df.copy(), t_k_arr, False)\n",
    "plot_training(results, t_k_arr, metrics.mean_absolute_error)\n",
    "plt.show()\n",
    "plot_training(results, t_k_arr, metrics.root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "results = train(int_5km_10days_14_8rain_df.copy(), t_k_arr, False)\n",
    "plot_training(results, t_k_arr, metrics.mean_absolute_error)\n",
    "plt.show()\n",
    "plot_training(results, t_k_arr, metrics.root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a Different Time of Day (0800 instead of 1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "results = train(int_5km_10days_8_df.copy(), t_k_arr)\n",
    "\n",
    "plot_training(results, t_k_arr, metrics.mean_absolute_error)\n",
    "plt.show()\n",
    "plot_training(results, t_k_arr, metrics.root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "results = train(int_5km_10days_8_df.copy(), t_k_arr, False)\n",
    "\n",
    "plot_training(results, t_k_arr, metrics.mean_absolute_error)\n",
    "plt.show()\n",
    "plot_training(results, t_k_arr, metrics.root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(pr)\n",
    "reload(ev)\n",
    "\n",
    "X = int_1200_df.copy()\n",
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "# Standardize weather\n",
    "for cov in ['temperature', 'humidity', 'wind', 'rain']:\n",
    "    X[cov] = (X[cov] - np.mean(X[cov])) / np.var(X[cov])\n",
    "    \n",
    "X = X.assign(year=map(lambda x: x.year, X.date_local))\n",
    "\n",
    "X = X[(X.year==2010)]\n",
    "\n",
    "\n",
    "results_baseline, results_auto, results_temp_humid, results_all = [], [], [], []\n",
    "for t_k in t_k_arr:\n",
    "    print 'Starting t_k=%d' % t_k\n",
    "    \"\"\"\n",
    "    # Filter out predicting before fire started\n",
    "    legit_series = pd.Series(index=X.index)\n",
    "    for clust in X.cluster_id.unique():\n",
    "        clust_df = X[X.cluster_id==clust]\n",
    "        legit_day = np.min(clust_df.date_local) + du.INC_ONE_DAY * (t_k+1)\n",
    "        legit_series[clust_df[clust_df.date_local>=legit_day].index]=1\n",
    "    \n",
    "    X = X[legit_series==1]\n",
    "    \"\"\"\n",
    "    X_t = pr.PoissonRegressionModel(t_k, []).add_autoregressive_col(X, t_k+1)\n",
    "    \n",
    "    results_baseline.append(metrics.mean_absolute_error(X_t.num_det, np.exp(X_t.num_det_prev_log)-1))\n",
    "    \n",
    "    prm = pr.PoissonRegressionModel(t_k=t_k, covariates=[])\n",
    "    results, years = ev.leave_none_out(prm, X_t)\n",
    "    results_auto.append(metrics.mean_absolute_error(*np.concatenate(results, axis=1)))\n",
    "    \n",
    "    prm = pr.PoissonRegressionModel(t_k=t_k, covariates=['temperature', 'humidity'])\n",
    "    results, years = ev.leave_none_out(prm, X_t)\n",
    "    results_temp_humid.append(metrics.mean_absolute_error(*np.concatenate(results, axis=1)))\n",
    "    \n",
    "    prm = pr.PoissonRegressionModel(t_k=t_k, covariates=['temperature', 'humidity', 'wind', 'rain'])\n",
    "    results, years = ev.leave_none_out(prm, X_t)\n",
    "    results_all.append(metrics.mean_absolute_error(*np.concatenate(results, axis=1)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_k_arr+1, results_baseline, \"kv--\", label=\"Baseline\", linewidth=2)\n",
    "plt.plot(t_k_arr+1, results_auto, \"gs--\", label=\"Autoregression\", linewidth=2)\n",
    "plt.plot(t_k_arr+1, results_temp_humid, \"r^--\", label=\"Temp/hum\", linewidth=2)\n",
    "plt.plot(t_k_arr+1, results_all, \"bo--\", label=\"All weather\", linewidth=2)\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "lgd = plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel(\"Day of forecast (k)\")\n",
    "plt.xticks(t_k_arr+1)\n",
    "plt.ylabel(\"Mean absolute error (2007-2016)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_df = load_integrated_df(os.path.join(DATA_DIR, 'archived/cluster/clust_feat_df_5.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify old data to work with new code\n",
    "clust_df['date_local'] = np.array(map(lambda x: dt.datetime(int(x), 1, 1), clust_df.year)) + np.array(map(lambda x: dt.timedelta(int(x) - 1), clust_df.dayofyear))\n",
    "clust_df.rename(columns={'temp': 'temperature', 'cluster': 'cluster_id', 'n_det': 'num_det'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(pr)\n",
    "reload(ev)\n",
    "\n",
    "X = clust_df.copy()\n",
    "t_k_arr = np.arange(0, 5)\n",
    "\n",
    "# Standardize weather\n",
    "for cov in ['temperature', 'humidity', 'wind', 'rain']:\n",
    "    X[cov] = (X[cov] - np.mean(X[cov])) / np.var(X[cov])\n",
    "    \n",
    "X = X.assign(year=map(lambda x: x.year, X.date_local))\n",
    "\n",
    "\n",
    "\n",
    "results_baseline, results_auto, results_temp_humid, results_all = [], [], [], []\n",
    "for t_k in t_k_arr:\n",
    "    print 'Starting t_k=%d' % t_k\n",
    "    \"\"\"\n",
    "    # Filter out predicting before fire started\n",
    "    legit_series = pd.Series(index=X.index)\n",
    "    for clust in X.cluster_id.unique():\n",
    "        clust_df = X[X.cluster_id==clust]\n",
    "        legit_day = np.min(clust_df.date_local) + du.INC_ONE_DAY * (t_k+1)\n",
    "        legit_series[clust_df[clust_df.date_local>=legit_day].index]=1\n",
    "    \n",
    "    X = X[legit_series==1]\n",
    "    \"\"\"\n",
    "    X_t = pr.PoissonRegressionModel(t_k, []).add_autoregressive_col(X, t_k+1)\n",
    "    \n",
    "    results_baseline.append(metrics.mean_absolute_error(X_t.num_det, np.exp(X_t.num_det_prev_log)-1))\n",
    "    \n",
    "    prm = pr.PoissonRegressionModel(t_k=t_k, covariates=[])\n",
    "    results, years = ev.cross_validation_years(prm, X_t)\n",
    "    results_auto.append(metrics.mean_absolute_error(*np.concatenate(results, axis=1)))\n",
    "    \n",
    "    prm = pr.PoissonRegressionModel(t_k=t_k, covariates=['temperature', 'humidity'])\n",
    "    results, years = ev.cross_validation_years(prm, X_t)\n",
    "    results_temp_humid.append(metrics.mean_absolute_error(*np.concatenate(results, axis=1)))\n",
    "    \n",
    "    prm = pr.PoissonRegressionModel(t_k=t_k, covariates=['temperature', 'humidity', 'wind', 'rain'])\n",
    "    results, years = ev.cross_validation_years(prm, X_t)\n",
    "    results_all.append(metrics.mean_absolute_error(*np.concatenate(results, axis=1)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_k_arr+1, results_baseline, \"kv--\", label=\"Baseline\", linewidth=2)\n",
    "plt.plot(t_k_arr+1, results_auto, \"gs--\", label=\"Autoregression\", linewidth=2)\n",
    "plt.plot(t_k_arr+1, results_temp_humid, \"r^--\", label=\"Temp/hum\", linewidth=2)\n",
    "plt.plot(t_k_arr+1, results_all, \"bo--\", label=\"All weather\", linewidth=2)\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "lgd = plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel(\"Day of forecast (k)\")\n",
    "plt.xticks(t_k_arr+1)\n",
    "plt.ylabel(\"Mean absolute error (2007-2016)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clust_df.copy()\n",
    "t_k = 4\n",
    "\n",
    "X_t = pr.PoissonRegressionModel(t_k, []).add_autoregressive_col(X, t_k+1)\n",
    "\n",
    "prm = pr.PoissonRegressionModel(t_k=t_k, covariates=['temperature', 'humidity', 'wind', 'rain'])\n",
    "results, years = ev.cross_validation_years(prm, X_t)\n",
    "print metrics.mean_absolute_error(*np.concatenate(results, axis=1))\n",
    "print prm.fit_result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get predictors\n",
    "import old_code.prediction.evaluation as ev_o\n",
    "import old_code.prediction.cluster_regression as cr\n",
    "reload(ev_o)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from old_code.prediction.evaluation import kill_nanners\n",
    "mets_baseline = dict()\n",
    "mets_mem = dict()\n",
    "mets_temphum = dict()\n",
    "mets_weather = dict()\n",
    "met = \"MeanAbsErr\"\n",
    "clust_df_orig = load_integrated_df(os.path.join(DATA_DIR, 'archived/cluster/clust_feat_df_5.pkl'))\n",
    "cdf_with_stuff = cr.add_autoreg_and_n_det(clust_df_orig.copy(), autoreg_cols=10, t_k_max=0, zero_padding=False)\n",
    "cdf_with_stuff = kill_nanners(cdf_with_stuff.copy(), [\"temp\", \"humidity\", \"wind\", \"rain_del_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t_k = 4\n",
    "\n",
    "for t_k in range(max_t_k,-1,-1):\n",
    "    legit_series = pd.Series(index=cdf_with_stuff.index)\n",
    "    for clust in cdf_with_stuff.cluster.unique():\n",
    "        clust_df = cdf_with_stuff[cdf_with_stuff.cluster==clust]\n",
    "        legit_day = np.min(clust_df.dayofyear) + t_k\n",
    "        legit_series[clust_df[clust_df.dayofyear >= legit_day].index] = 1\n",
    "    y_t_k_base = cdf_with_stuff[legit_series == 1]['n_det']\n",
    "    y_hat_t_k_base = np.exp(cdf_with_stuff[legit_series == 1][\"autoreg_%d\" % (1 + t_k)]) - 1\n",
    "\n",
    "    # Baseline\n",
    "    mets_baseline[t_k] = (ev_o.evaluate_glm(y_t_k_base, y_hat_t_k_base, metric=met))\n",
    "    \n",
    "    # models\n",
    "    mets_mem[t_k] = ev_o.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series, metrics=[met])\n",
    "    mets_temphum[t_k] = ev_o.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\"], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series, metrics=[met])\n",
    "    mets_weather[t_k] = ev_o.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\",\"wind\",\"rain_del_2\"], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series, metrics=[met])\n",
    "    \n",
    "    print \"done with t_k %d\" % t_k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "n_t_k = 5\n",
    "t_k_arr = np.arange(n_t_k)\n",
    "mets = [\"MeanAbsErr\"]\n",
    "i = 0\n",
    "for met in mets:\n",
    "    base_arr = np.array(map(lambda x: mets_baseline[x], t_k_arr))\n",
    "    mem_arr = np.array(map(lambda x: mets_mem[x][i], t_k_arr))\n",
    "    temphum_arr = np.array(map(lambda x: mets_temphum[x][i], t_k_arr))\n",
    "    weather_arr = np.array(map(lambda x: mets_weather[x][i], t_k_arr))\n",
    "    \n",
    "    plt.plot(t_k_arr+1, base_arr, \"kv--\", label=\"Baseline\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, mem_arr, \"gs--\", label=\"Autoregression\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, temphum_arr, \"r^--\", label=\"Temp/hum\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, weather_arr, \"bo--\", label=\"All weather\", linewidth=2)\n",
    "    \n",
    "    matplotlib.rcParams.update({'font.size': 14})\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlabel(\"Day of forecast (k)\")\n",
    "    plt.xticks(t_k_arr+1)\n",
    "    plt.ylabel(\"Mean absolute error (2007-2016)\")\n",
    "    #plt.savefig(\"pics/mae.png\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try old code with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df_mod = int_df.copy()\n",
    "\n",
    "# Modify new data to work with old code\n",
    "int_df_mod['dayofyear'] = np.array(map(lambda x: du.dayofyear_from_datetime(x), int_df_mod.date_local))\n",
    "int_df_mod = int_df_mod.assign(year=map(lambda x: x.year, int_df_mod.date_local))\n",
    "int_df_mod.rename(columns={'temperature': 'temp', 'cluster_id': 'cluster', 'num_det': 'n_det'}, inplace=True)\n",
    "int_df_mod['alt_cluster'] = np.empty(int_df_mod.shape[0]).fill(np.nan)\n",
    "int_df_mod['rain_del_2'] = int_df_mod['rain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mets_baseline = dict()\n",
    "mets_mem = dict()\n",
    "mets_temphum = dict()\n",
    "mets_weather = dict()\n",
    "met = \"MeanAbsErr\"\n",
    "\n",
    "#clust_df = load_integrated_df(os.path.join(DATA_DIR, 'archived/cluster/clust_feat_df_5.pkl'))\n",
    "\n",
    "cdf_with_stuff_new = cr.add_autoreg_and_n_det(int_df_mod.copy(), autoreg_cols=10, t_k_max=0, zero_padding=False)\n",
    "cdf_with_stuff_new = kill_nanners(cdf_with_stuff_new.copy(), [\"temp\", \"humidity\", \"wind\", \"rain_del_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t_k = 4\n",
    "\n",
    "for t_k in range(max_t_k,-1,-1):\n",
    "    legit_series = pd.Series(index=cdf_with_stuff_new.index)\n",
    "    for clust in cdf_with_stuff_new.cluster.unique():\n",
    "        clust_df = cdf_with_stuff_new[cdf_with_stuff_new.cluster==clust]\n",
    "        legit_day = np.min(int_df_mod.dayofyear) + (t_k+1)\n",
    "        legit_series[clust_df[clust_df.dayofyear >= legit_day].index] = 1\n",
    "    y_t_k_base = cdf_with_stuff_new[legit_series == 1]['n_det']\n",
    "    y_hat_t_k_base = np.exp(cdf_with_stuff_new[legit_series == 1][\"autoreg_%d\" % (1 + t_k)]) - 1\n",
    "\n",
    "    # Baseline\n",
    "    mets_baseline[t_k] = (ev_o.evaluate_glm(y_t_k_base, y_hat_t_k_base, metric=met))\n",
    "    \n",
    "    # models\n",
    "    mets_mem[t_k] = ev_o.cross_validation_evaluation(cdf_with_stuff_new[legit_series == 1], autoreg=1, t_k=t_k, weather_vars=[], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series, metrics=[met])\n",
    "    mets_temphum[t_k] = ev_o.cross_validation_evaluation(cdf_with_stuff_new[legit_series == 1], autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\"], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series, metrics=[met])\n",
    "    mets_weather[t_k] = ev_o.cross_validation_evaluation(cdf_with_stuff_new[legit_series == 1], autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\",\"wind\",\"rain_del_2\"], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series, metrics=[met])\n",
    "    \n",
    "    print \"done with t_k %d\" % t_k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "n_t_k = 5\n",
    "t_k_arr = np.arange(n_t_k)\n",
    "mets = [\"MeanAbsErr\"]\n",
    "i = 0\n",
    "for met in mets:\n",
    "    base_arr = np.array(map(lambda x: mets_baseline[x], t_k_arr))\n",
    "    mem_arr = np.array(map(lambda x: mets_mem[x][i], t_k_arr))\n",
    "    temphum_arr = np.array(map(lambda x: mets_temphum[x][i], t_k_arr))\n",
    "    weather_arr = np.array(map(lambda x: mets_weather[x][i], t_k_arr))\n",
    "    \n",
    "    plt.plot(t_k_arr+1, base_arr, \"kv--\", label=\"Baseline\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, mem_arr, \"gs--\", label=\"Autoregression\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, temphum_arr, \"r^--\", label=\"Temp/hum\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, weather_arr, \"bo--\", label=\"All weather\", linewidth=2)\n",
    "    \n",
    "    matplotlib.rcParams.update({'font.size': 14})\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlabel(\"Day of forecast (k)\")\n",
    "    plt.xticks(t_k_arr+1)\n",
    "    plt.ylabel(\"Mean absolute error (2007-2016)\")\n",
    "    #plt.savefig(\"pics/mae.png\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
