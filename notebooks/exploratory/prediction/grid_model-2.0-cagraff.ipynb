{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "\n",
    "REP_DIR = \"/home/cagraff/Documents/dev/fire_prediction/\"\n",
    "SRC_DIR = REP_DIR + 'src/'\n",
    "DATA_DIR = REP_DIR + 'data/'\n",
    "\n",
    "# --- System imports\n",
    "import numpy as np\n",
    "import os as os\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# --- Package imports\n",
    "import evaluation.evaluate_model as evm\n",
    "import helper.loaders as load\n",
    "import helper.multidata_wrapper as mdw\n",
    "import visualization.plotting as vplt\n",
    "import helper.date_util as du\n",
    "\n",
    "from models import grid_predictor as gp\n",
    "from models import poisson_regression as pr\n",
    "from models import active_ignition_grid as aig\n",
    "from models import poisson_regression_grid as prg\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days to predict\n",
    "T_K_MAX = 5\n",
    "T_K_ARR = np.arange(1,T_K_MAX+1)\n",
    "\n",
    "# Years to use\n",
    "YEAR_START, YEAR_END = 2007, 2016\n",
    "YEARS_ARR = np.arange(YEAR_START, YEAR_END+1)\n",
    "\n",
    "# === DATA FILES ===\n",
    "ignition_cube_src = os.path.join(DATA_DIR, 'interim/modis/fire_cube/fire_ignition_cube_modis_alaska_2007-2016.pkl')\n",
    "detection_cube_src = os.path.join(DATA_DIR, 'interim/modis/fire_cube/fire_detection_cube_modis_alaska_2007-2016.pkl')\n",
    "weather_proc_region_src = os.path.join(DATA_DIR, 'interim/gfs/weather_proc/weather_proc_gfs_4_alaska_2007-2016.pkl')\n",
    "        \n",
    "# Build list of file names (based on t_k)\n",
    "integrated_cluster_df_fmt = 'interim/integrated/fire_weather/fire_weather_integrated_gfs_4_modis_5km_10days_1400_%dk_alaska_2007-2016.pkl'\n",
    "integrated_cluster_df_src_list = map(lambda k: (k, os.path.join(DATA_DIR, integrated_cluster_df_fmt % k)), T_K_ARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA LOADING ===\n",
    "X_ignition_c, Y_detection_c = evm.setup_ignition_data(ignition_cube_src, detection_cube_src)\n",
    "weather_proc_region = load.load_pickle(weather_proc_region_src)\n",
    "\n",
    "X_active_df = {}\n",
    "for t_k,f_src in integrated_cluster_df_src_list:\n",
    "    X_active_df[t_k] = evm.setup_active_fire_data(f_src)\n",
    "    \n",
    "BOUNDING_BOX = weather_proc_region.bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-grid baselines\n",
    "def only_zero_model(covariates):\n",
    "    model = aig.ActiveIgnitionGridModel(None, None)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def no_ignition_model_poisson(covariates):\n",
    "    afm = gp.GridPredictorModel(pr.PoissonRegressionModel(covariates), BOUNDING_BOX)\n",
    "    model = aig.ActiveIgnitionGridModel(afm, None)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid models\n",
    "def no_ignition_grid_model_poisson(covariates):\n",
    "    afm = prg.PoissonRegressionGridModel(covariates)\n",
    "    model = aig.ActiveIgnitionGridModel(afm, None)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_y(y, t_k_arr):\n",
    "    y_dict = {}\n",
    "    for t_k in t_k_arr:\n",
    "        # Shift y by t_k days\n",
    "        shape = np.shape(y.values)[:2]+(t_k,)\n",
    "        y_new = np.concatenate((y.values, np.zeros(shape)), axis=2)\n",
    "        y_new = y_new[:,:,t_k:]\n",
    "        \n",
    "        # Convert y_new to an xarray dataset\n",
    "        y_ds = xr.DataArray(y_new, coords={'time': pd.to_datetime(y.dates)}, dims=('y', 'x', 'time'))\n",
    "        \n",
    "        y_dict[t_k] = y_ds\n",
    "        \n",
    "    return y_dict\n",
    "\n",
    "def build_x_active(X, t_k_arr):\n",
    "    X_dict = {}\n",
    "    for t_k in t_k_arr:\n",
    "        dates = pd.to_datetime(np.array(X[t_k]['date_local']))\n",
    "        X_ds = xr.Dataset({'num_det': (('time'), X[t_k]['num_det']),\n",
    "                           'temperature': (('time'), X[t_k]['temperature']),\n",
    "                           'humidity': (('time'), X[t_k]['humidity']),\n",
    "                           'wind': (('time'), X[t_k]['wind']),\n",
    "                           'rain': (('time'), X[t_k]['rain']),\n",
    "                           'lat_centroid': (('time'), X[t_k]['lat_centroid']),\n",
    "                           'lon_centroid': (('time'), X[t_k]['lon_centroid']),\n",
    "                           'num_det_target': (('time'), X[t_k]['num_det_target'])},\n",
    "                          {'time': dates})\n",
    "        X_dict[t_k] = mdw.MultidataWrapper((X_ds,None))\n",
    "    return X_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_n_days = 5\n",
    "\n",
    "def fill_missing_value(data, date_ind):                                                    \n",
    "    \"\"\"\n",
    "    Try to replace with closest prev day in range [1, fill_n_days].                                                \n",
    "\n",
    "    If no non-nan value is found, replaces with mean of all values at the given lat/lon.                           \n",
    "    \"\"\" \n",
    "    for day_offset in range(1,fill_n_days+1):                                                                 \n",
    "        new_date_ind = date_ind - day_offset                                                                       \n",
    "\n",
    "        if new_date_ind < 0:                                                                                       \n",
    "            break                                                                                                  \n",
    "\n",
    "        val = data[:, :, new_date_ind]                                                                 \n",
    "\n",
    "        if not np.any(np.isnan(val)):                                                                                      \n",
    "            return val                                                                                             \n",
    "\n",
    "    return np.nanmean(data[:, :, :], axis=2)\n",
    "\n",
    "def get_date_index(weather_data, target_datetime):\n",
    "        date_ind = np.searchsorted(weather_data.dates, target_datetime, side='left')\n",
    "\n",
    "        # Check if left or right element is closer\n",
    "        if date_ind != 0:\n",
    "            date_ind_left, date_ind_curr = date_ind-1, date_ind\n",
    "\n",
    "            dist_left = abs((weather_data.dates[date_ind_left] - target_datetime).total_seconds())\n",
    "            dist_curr = abs((weather_data.dates[date_ind_curr] - target_datetime).total_seconds())\n",
    "            \n",
    "            if dist_left < dist_curr:\n",
    "                date_ind = date_ind_left\n",
    "\n",
    "        return date_ind\n",
    "    \n",
    "def get_weather_variables(vals,weather_data, target_datetime, covariates):                                                             \n",
    "    # Get date index\n",
    "    date_ind = get_date_index(weather_data, target_datetime)                                                  \n",
    "\n",
    "    #vals = []\n",
    "    for key in covariates:                                                                           \n",
    "        data = weather_data[key].values                                                                            \n",
    "        val = data[:, :, date_ind]                                                                 \n",
    "\n",
    "        if np.any(np.isnan(val)):\n",
    "            val = fill_missing_value(data, date_ind)                                        \n",
    "\n",
    "        #vals.append(val)                                                                                           \n",
    "        vals[key].append(val)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_x_grid(X, y, t_k_arr):\n",
    "    X_dict = {}\n",
    "    for t_k in t_k_arr:\n",
    "        \n",
    "        # Shift y by t_k days\n",
    "        shape = np.shape(y.values)[:2]+(t_k,)\n",
    "        y_new = np.concatenate((y.values, np.zeros(shape)), axis=2)\n",
    "        y_new = y_new[:,:,t_k:]\n",
    "        \n",
    "        # Build grid of weather\n",
    "        vals = defaultdict(list)\n",
    "        for date in Y_detection_c.dates:\n",
    "            time = 14\n",
    "            date += du.INC_ONE_DAY * t_k # For row t, store weather(t+k)\n",
    "            target_datetime = dt.datetime.combine(date, dt.time(time, 0, 0, tzinfo=du.TrulyLocalTzInfo(153, du.round_to_nearest_quarter_hour)))\n",
    "            \n",
    "            get_weather_variables(vals, X, target_datetime, ['temperature','humidity','wind','rain'])\n",
    "\n",
    "        for k,v in vals.iteritems():\n",
    "            vals[k] = np.rollaxis(np.array(v), 0, 3)  \n",
    "        \n",
    "        dates = pd.to_datetime(np.array(y.dates))\n",
    "        X_ds = xr.Dataset({'num_det': (('y','x','time'), y.values),\n",
    "                           'num_det_target': (('y', 'x', 'time'), y_new),\n",
    "                           'temperature': (('y','x','time'), vals['temperature']),\n",
    "                           'humidity': (('y','x','time'), vals['humidity']),\n",
    "                           'wind': (('y','x','time'), vals['wind']),\n",
    "                           'rain': (('y','x','time'), vals['rain'])},\n",
    "                          {'time': dates})\n",
    "                       \n",
    "        X_dict[t_k] = mdw.MultidataWrapper((X_ds,None))\n",
    "        \n",
    "        print 'T_k=%d' % t_k\n",
    "    return X_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'None': [],\n",
    "              'Temp/Humid': ['temperature', 'humidity'],\n",
    "              'All': ['temperature','humidity','wind','rain']}\n",
    "YEARS_TEST = range(2007,2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_grid_dict = build_y(Y_detection_c, T_K_ARR)\n",
    "X_active_dict = build_x_active(X_active_df, T_K_ARR)\n",
    "X_grid_dict = build_x_grid(weather_proc_region, Y_detection_c, T_K_ARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test baselines\n",
    "#results_only_zero = evm.evaluate_model_params(only_zero_model, {'None': []}, X_active_dict, y_grid_dict, YEARS_TEST, T_K_ARR)\n",
    "reload(cv)\n",
    "reload(gp)\n",
    "reload(evm)\n",
    "reload(aig)\n",
    "reload(pr)\n",
    "results_no_ig, models_no_ig = evm.evaluate_model_params(no_ignition_model_poisson, param_dict, X_active_dict, y_grid_dict, YEARS_TEST, T_K_ARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vplt.plot_results_grid([(results_no_ig[0], 'Poisson (No Ign.)'), (results_no_ig[1], 'Poisson (No Ign.)')], T_K_ARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_ig_grid, models_no_ig_grid = evm.evaluate_model_params(no_ignition_grid_model_poisson, param_dict, X_grid_dict, y_grid_dict, YEARS_TEST, T_K_ARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vplt.plot_results_grid([(results_no_ig_grid, 'Poisson Grid (No Ign.)')], T_K_ARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cell_encoding(data):\n",
    "    for i in range(33):\n",
    "        for j in range(55):\n",
    "            enc = np.zeros((5,5,1100))\n",
    "            enc[i,j,:]=1\n",
    "            enc = enc.flatten()\n",
    "            data.append(('cell_%d_%d'%(i,j),enc))\n",
    "\n",
    "    print [k[0] for k in data][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(evm)\n",
    "reload(aig)\n",
    "reload(gp)\n",
    "reload(pr)\n",
    "import evaluation.cross_validation as cv\n",
    "reload(cv)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
