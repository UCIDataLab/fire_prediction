{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import cPickle\n",
    "import os\n",
    "os.chdir('/Users/zbutler/research/fire_prediction')\n",
    "from data import data\n",
    "from prediction.cluster_regression import ClusterRegression\n",
    "from prediction.poisson_regression import evaluate_glm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_feat_df = data.load_clust_feat_df(clust_thresh=5)\n",
    "clust_feat_df.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = ClusterRegression(clust_feat_df, 5, 'unused', 10)\n",
    "cr.clust_df.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_except_year(year, rng=(2007,2016)):\n",
    "    return [x for x in range(rng[0],rng[1]+1) if x!=year]\n",
    "cr.fit(range(2007,2017), 1)\n",
    "cr.fit_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Len of feat df: \" + str(len(clust_feat_df))\n",
    "print \"corr: \" + str(pearsonr(clust_feat_df.rain[True - np.isnan(clust_feat_df.rain)], clust_feat_df.n_det[True - np.isnan(clust_feat_df.rain)]))\n",
    "plt.scatter(np.array(clust_feat_df.rain), np.array(clust_feat_df.n_det))\n",
    "plt.xlabel('rain')\n",
    "plt.ylabel('fire detections in this cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cr = ClusterRegression(clust_feat_df, 5, 'unused', 10)\n",
    "baseline_res = dict()\n",
    "memory_1_res = dict()\n",
    "memory_5_res = dict()\n",
    "weather_1_res = dict()\n",
    "weather_5_res = dict()\n",
    "eval_metrics = [\"MSE\", \"MedianSE\"]\n",
    "for met in eval_metrics:\n",
    "    baseline_res[met] = []\n",
    "    memory_1_res[met] = []\n",
    "    memory_5_res[met] = []\n",
    "    weather_1_res[met] = []\n",
    "    weather_5_res[met] = []\n",
    "    \n",
    "for year in xrange(2007, 2017):\n",
    "    years = all_except_year(year)\n",
    "    test_df = clust_feat_df[clust_feat_df.year==year]\n",
    "    y = test_df.n_det\n",
    "    non_nan_inds = np.logical_not(np.isnan(test_df.temp))\n",
    "    stupid = np.where(non_nan_inds)[0]\n",
    "    y_non_nan = y[non_nan_inds]\n",
    "    base_fit = test_df.autoreg_1\n",
    "    memory_1 = cr.fit(years, n_autoreg=1, weather_vars=[])\n",
    "    memory_5 = cr.fit(years, n_autoreg=5, weather_vars=[])\n",
    "    weather_1 = cr.fit(years, n_autoreg=1, weather_vars=['temp','humidity','wind','rain'])\n",
    "    weather_5 = cr.fit(years, n_autoreg=5, weather_vars=['temp','humidity','wind','rain'])\n",
    "    for met in eval_metrics:\n",
    "        baseline_res[met].append(evaluate_glm(y_non_nan, base_fit[non_nan_inds], metric=met))\n",
    "        memory_1_res[met].append(evaluate_glm(y_non_nan, np.array(memory_1.predict(test_df))[stupid], metric=met))\n",
    "        memory_5_res[met].append(evaluate_glm(y_non_nan, np.array(memory_5.predict(test_df))[stupid], metric=met))\n",
    "        weather_1_res[met].append(evaluate_glm(y_non_nan, weather_1.predict(test_df), metric=met))\n",
    "        weather_5_res[met].append(evaluate_glm(y_non_nan, weather_5.predict(test_df), metric=met))\n",
    "    print \"done with year %d\" % year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make plots\n",
    "years = np.arange(2013, 2017)\n",
    "plt.plot(years, baseline_res[\"MSE\"][-4:], 'bs', label=\"Baseline\")\n",
    "plt.plot(years, memory_1_res[\"MSE\"][-4:], 'rs', label=\"Memory(1)\")\n",
    "plt.plot(years, memory_5_res[\"MSE\"][-4:], 'ro', label=\"Memory(5)\")\n",
    "plt.plot(years, weather_1_res[\"MSE\"][-4:], 'gs', label=\"Weather(1)\")\n",
    "plt.plot(years, weather_5_res[\"MSE\"][-4:], 'go', label=\"Weather(5)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"MSE\")\n",
    "ax = plt.gca()\n",
    "ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myyear = 2015\n",
    "years = all_except_year(myyear)\n",
    "weather_1 = cr.fit(years, n_autoreg=1, weather_vars=['temp','humidity','wind','rain'])\n",
    "test_df = clust_feat_df[clust_feat_df.year==myyear]\n",
    "y = test_df.n_det\n",
    "non_nan_inds = np.logical_not(np.isnan(test_df.temp))\n",
    "stupid = np.where(non_nan_inds)[0]\n",
    "y_hat = weather_1.predict(test_df)\n",
    "plt.scatter(y[non_nan_inds], y_hat)\n",
    "plt.xlabel(\"y\")\n",
    "plt.ylabel(\"yhat\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = ClusterRegression(clust_feat_df, 5, 'unused', 10)\n",
    "weather_1 = cr.fit(years, n_autoreg=1, weather_vars=['temp','humidity','wind','rain'])\n",
    "memory_1 = cr.fit(years, n_autoreg=1, weather_vars=[])\n",
    "clust = 890\n",
    "clust_df = test_df[test_df.cluster==clust].sort('dayofyear')\n",
    "y_clust = clust_df.n_det\n",
    "non_nan_days = np.logical_not(np.isnan(clust_df.temp))\n",
    "stupid = np.where(non_nan_days)[0]\n",
    "y_hat_clust = np.zeros(len(y_clust))\n",
    "y_hat_clust[stupid] = weather_1.predict(clust_df)\n",
    "y_hat_mem = memory_1.predict(clust_df)\n",
    "days = clust_df.dayofyear\n",
    "plt.plot(days, y_clust, 'r--', label='y')\n",
    "plt.plot(days, y_hat_clust, 'b--', label='yhat')\n",
    "plt.plot(days, y_hat_mem, 'g--', label='memory')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "weather_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why are these models learning no autoregressive component?\n",
    "plt.scatter(np.log(clust_feat_df.n_det+1), np.log(clust_feat_df.autoreg_1+1))\n",
    "plt.xlabel(\"Number of detections today\")\n",
    "plt.ylabel(\"Number of detections yesterday\")\n",
    "plt.show()\n",
    "nans = np.isnan(clust_feat_df.temp)\n",
    "print \"autoreg correlation: \" + str(pearsonr(clust_feat_df.n_det, clust_feat_df.autoreg_1))\n",
    "print \"temp correlation: \" + str(pearsonr(clust_feat_df.n_det[~nans], clust_feat_df.temp[~nans]))\n",
    "print \"humidity correlation: \" + str(pearsonr(clust_feat_df.n_det[~nans], clust_feat_df.humidity[~nans]))\n",
    "print \"wind correlation: \" + str(pearsonr(clust_feat_df.n_det[~nans], clust_feat_df.wind[~nans]))\n",
    "print \"rain correlation: \" + str(pearsonr(clust_feat_df.n_det[~nans], clust_feat_df.rain[~nans]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print cr.clust_df.iloc[0:5]\n",
    "print \"autoreg correlation: \" + str(pearsonr(cr.clust_df.n_det, cr.clust_df.autoreg_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stats for every year\n",
    "for nonyear in xrange(2007,2017):\n",
    "    ft = cr.fit(all_except_year(nonyear), 1, weather_vars=[])\n",
    "    print \"%d: %f\" % (nonyear, ft.params[\"autoreg_1\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coefficients and pearson correlations for each feature and each year\n",
    "for i in xrange(2,11):\n",
    "    name = \"autoreg_%d\" % i\n",
    "    if name in clust_feat_df.columns:\n",
    "        del clust_feat_df[name]\n",
    "        \n",
    "my_cols = [\"n_det\", \"autoreg_1\", \"temp\", \"humidity\", \"wind\", \"rain\"]\n",
    "for year in xrange(2007, 2017):\n",
    "    annual_df = clust_feat_df[clust_feat_df.year==year]\n",
    "    non_nans = annual_df[~np.isnan(annual_df.rain)]\n",
    "    corrs = map(lambda x: pearsonr(non_nans.n_det, non_nans[x])[0], my_cols)\n",
    "    width = .35       # the width of the bars\n",
    "    ind = np.arange(len(my_cols))\n",
    "    fig, ax = plt.subplots(figsize=(13,6))\n",
    "    plt.title(str(year))\n",
    "    rects1 = ax.bar(ind, corrs, width, color='b')\n",
    "    ft = cr.fit([year], 1)\n",
    "    ft_dict = dict(ft.params)\n",
    "    ft_dict['n_det'] = 0.\n",
    "    params = map(lambda x: ft_dict[x], my_cols)\n",
    "    rects2 = ax.bar(ind + width, params, width, color='r')\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(my_cols)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# staggered rain correlation\n",
    "for t in xrange(0,5):\n",
    "    t_rain_dict = dict()\n",
    "    for clust in clust_feat_df.cluster.unique():\n",
    "        clust_df = clust_feat_df[clust_feat_df.cluster == clust]\n",
    "        days = clust_df.dayofyear.unique()\n",
    "        for day in days:\n",
    "            day_row = clust_df[clust_df.dayofyear==day]\n",
    "            name = day_row.iloc[0].name\n",
    "            delayed_rain_day = day - t\n",
    "            if delayed_rain_day in days:\n",
    "                rain_val = clust_df[clust_df.dayofyear==delayed_rain_day].iloc[0].rain\n",
    "                if np.isnan(rain_val):\n",
    "                    t_rain_dict[name] = 0.\n",
    "                else:\n",
    "                    t_rain_dict[name] = clust_df[clust_df.dayofyear==delayed_rain_day].iloc[0].rain\n",
    "            else:\n",
    "                t_rain_dict[name] = 0.\n",
    "    clust_feat_df[\"rain_del_%d\" % t] = pd.Series(t_rain_dict)\n",
    "print \"sweg bitch\"\n",
    "print clust_feat_df.iloc[0:10].rain_del_1\n",
    "corrs = map(lambda x: pearsonr(clust_feat_df.n_det, clust_feat_df[\"rain_del_%d\" % x]), range(0,5))\n",
    "print \"yala\"\n",
    "plt.plot(range(0,5), corrs, 'b--')\n",
    "plt.xlabel(\"Rain delay\")\n",
    "plt.ylabel(\"Pearson correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot n_det and autoreg_1 for each cluster\n",
    "for clust in clust_feat_df.cluster.unique():\n",
    "    clust_df = clust_feat_df[clust_feat_df.cluster==clust].sort('dayofyear')\n",
    "    plt.plot(clust_df.dayofyear, clust_df.n_det, 'b--', label=\"n_det\")\n",
    "    plt.plot(clust_df.dayofyear, clust_df.autoreg_1, 'r--', label=\"autoreg_1\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    boop = raw_input('Press enter to continue or q to quit: ')\n",
    "    plt.close()\n",
    "    if boop.startswith('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation with binary over/under median\n",
    "mean = np.mean(clust_feat_df.n_det)\n",
    "over_under_n_det = clust_feat_df.n_det > mean\n",
    "over_under_autoreg = clust_feat_df.autoreg_1 > mean\n",
    "print \"binary corr: \" + str(pearsonr(over_under_n_det, over_under_autoreg))\n",
    "print \"mean: \" + str(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = cr.fit(range(2007,2017), 1, [])\n",
    "print ft.params\n",
    "plt.plot(np.sort(clust_feat_df.n_det))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_feat_df = clust_feat_df.copy()\n",
    "clipped_feat_df[clipped_feat_df.n_det > 10].n_det = 10\n",
    "clipped_CR = ClusterRegression(clipped_feat_df,5,'unused',2)\n",
    "clipped_ft = clipped_CR.fit(range(2007,2017),1,[])\n",
    "print clipped_ft.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df = cPickle.load(open(\"data/global_df.pkl\"))\n",
    "global_df['cluster'] = global_df['year']\n",
    "global_df['alt_cluster'] = np.nan\n",
    "global_cr = ClusterRegression(global_df, 5, 'unused', 2)\n",
    "global_ft = global_cr.fit(range(2007,2017),1,[])\n",
    "print global_ft.params\n",
    "annual_df = global_df[global_df.year==2013]\n",
    "plt.plot(annual_df.dayofyear, annual_df.n_det,'r--')\n",
    "plt.plot(annual_df.dayofyear, annual_df.autoreg_1,'b--')\n",
    "plt.plot(annual_df.dayofyear, annual_df.autoreg_2,'g--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction.cluster_regression import add_autoreg\n",
    "global_df['cluster'] = global_df['year']\n",
    "global_df = add_autoreg(global_df, 2)\n",
    "ft = smf.glm(\"n_det ~ autoreg_1\", data=global_df, family=sm.genmod.families.family.Poisson()).fit()\n",
    "ft.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stupid_glm = sm.GLM(global_df.n_det, np.log(global_df.autoreg_1+1), family=sm.genmod.families.family.Poisson()).fit()\n",
    "stupid_glm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prediction.cluster_regression as CR\n",
    "reload(CR)\n",
    "cr = CR.ClusterRegression(clust_feat_df, 5, 'unused', 5)\n",
    "ft = cr.fit(range(2007,2017),1,[])\n",
    "ft.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prediction.cluster_regression as CR\n",
    "reload(CR)\n",
    "cr = CR.ClusterRegression(clust_feat_df, 5, 'unused', 5)\n",
    "ft = cr.fit(range(2007,2017),5,[])\n",
    "ft.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
