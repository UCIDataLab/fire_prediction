{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels as sm\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('/Users/zbutler/research/fire_prediction')\n",
    "import prediction.poisson_regression as pr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load our dataset\n",
    "with open('data/global_df.pkl') as fpkl:\n",
    "    global_df = cPickle.load(fpkl)\n",
    "global_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic plots\n",
    "annual_df = global_df[(global_df.year == 2013) & (global_df.dayofyear > 150) & (global_df.dayofyear < 200)]\n",
    "#yearfloatarr = global_df.year + (global_df.dayofyear / 365.)\n",
    "plt.plot(annual_df.dayofyear, np.log(annual_df.n_det+1), 'r.')\n",
    "plt.title('number of detections per day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try making a prediction dataset. i guess this should be in carpentry/, i'll throw it there later\n",
    "def create_dataset(df, normalize_feats=True):\n",
    "    years = df.year.unique()\n",
    "    X = pd.DataFrame()\n",
    "    y = np.zeros((0))\n",
    "    for year in years:\n",
    "        annual_df = df[df.year == year]\n",
    "        max_day = np.max(annual_df.dayofyear)\n",
    "        min_day = np.min(annual_df.dayofyear)\n",
    "        X = pd.concat((X, annual_df[annual_df.dayofyear != max_day]))\n",
    "        y = np.concatenate((y, np.array(annual_df.n_det[annual_df.dayofyear != min_day])))\n",
    "    if normalize_feats:\n",
    "        X = (X - X.mean()) / X.std()\n",
    "    return X,y\n",
    "\n",
    "feat_df = global_df.loc[:,['dayofyear', 'humidity', 'n_clusters', 'n_det', 'temp', 'vpd', 'year']]\n",
    "X, y = create_dataset(feat_df)\n",
    "print X.iloc[0]\n",
    "print y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X_const = sm.add_constant(X)\n",
    "glm = sm.GLM(y, X_const, family=sm.genmod.families.family.Poisson(), missing='drop')\n",
    "glm_res = glm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print global_df.columns[[2,4,5,6,7]]\n",
    "glm_res.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "def train_test_split(df, years_in_test=1, normalize_feats=True, feat_cols=['dayofyear', 'n_det', 'vpd']):\n",
    "    years = df.year.unique()\n",
    "    perm = np.random.permutation(years)\n",
    "    test_years = perm[0:years_in_test]\n",
    "    train_years = perm[years_in_test:]\n",
    "    print \"Train years: \" + str(train_years)\n",
    "    print \"Test years: \" + str(test_years)\n",
    "    X_train = pd.DataFrame()\n",
    "    y_train = np.zeros((0))\n",
    "    for year in train_years:\n",
    "        annual_df = df[df.year == year]\n",
    "        max_day = np.max(annual_df.dayofyear)\n",
    "        min_day = np.min(annual_df.dayofyear)\n",
    "        X_train = pd.concat((X_train, annual_df.loc[(annual_df.dayofyear != max_day), feat_cols]))\n",
    "        y_train = np.concatenate((y_train, np.array(annual_df.n_det[annual_df.dayofyear != min_day])))\n",
    "    if normalize_feats:\n",
    "        X_mean = X_train.mean()\n",
    "        X_std = X_train.std()\n",
    "        X_train = (X_train - X_mean) / X_std\n",
    "    X_train = sm.add_constant(X_train)\n",
    "    \n",
    "    X_test = pd.DataFrame()\n",
    "    y_test = np.zeros((0))\n",
    "    y_hat_base = np.zeros((0))\n",
    "    for year in test_years:\n",
    "        annual_df = df[df.year == year]\n",
    "        max_day = np.max(annual_df.dayofyear)\n",
    "        min_day = np.min(annual_df.dayofyear)\n",
    "        X_test = pd.concat((X_test, annual_df.loc[(annual_df.dayofyear != max_day), feat_cols]))\n",
    "        y_test = np.concatenate((y_test, np.array(annual_df.n_det[annual_df.dayofyear != min_day])))\n",
    "        y_hat_base = np.concatenate((y_hat_base, np.array(annual_df.n_det[annual_df.dayofyear != max_day])))\n",
    "    if normalize_feats:\n",
    "        X_test = (X_test - X_mean) / X_std\n",
    "    X_test = sm.add_constant(X_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, y_hat_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, y_hat_base = train_test_split(global_df)\n",
    "X_train_2, y_train_2, X_test_2, y_test_2, y_hat_base_2 = train_test_split(global_df, normalize_feats=False, feat_cols=['n_det'])\n",
    "print \"Shapes: \" + str([X_train.shape, y_train.shape, X_test.shape, y_test.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = sm.GLM(y_train, X_train, family=sm.genmod.families.family.Poisson(), missing='drop')\n",
    "glm_res = glm.fit()\n",
    "print glm_res.summary()\n",
    "glm_2 = sm.GLM(y_train_2, X_train_2, family=sm.genmod.families.family.Poisson(), missing='drop')\n",
    "glm_res_2 = glm_2.fit()\n",
    "print glm_res_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_glm(y, y_hat, ignore_nans=True):\n",
    "    if ignore_nans:\n",
    "        non_nans = (1 - np.isnan(y_hat)).astype(bool)\n",
    "        y = y[non_nans]\n",
    "        y_hat = y_hat[non_nans]\n",
    "        print \"skipped %d\" %(len(y) - np.sum(non_nans))\n",
    "    return np.mean((y - y_hat)**2)\n",
    "y_hat = glm_res.predict(X_test)\n",
    "y_hat_train = glm_res.predict(X_train)\n",
    "y_hat_2 = glm_res_2.predict(X_test_2)\n",
    "print \"MSE training: \" + str(evaluate_glm(y_train, y_hat_train))\n",
    "print \"MSE model full: \" + str(evaluate_glm(y_test, y_hat))\n",
    "print \"MSE model auto: \" + str(evaluate_glm(y_test_2, y_hat_2))\n",
    "print \"MSE base: \" + str(evaluate_glm(y_test, y_hat_base))\n",
    "print \"MSE zeros: \" + str(evaluate_glm(y_test, np.zeros(len(y_test))))\n",
    "print np.mean((y_test - y_hat_base)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_nn = y_hat[np.logical_not(np.isnan(y_hat))]\n",
    "print \"mean: \" + str(np.mean(y_hat_nn))\n",
    "print \"max: \" + str(np.max(y_hat_nn))\n",
    "print \"min: \" + str(np.min(y_hat_nn))\n",
    "y_test_nn = y_test[np.logical_not(np.isnan(y_hat))]\n",
    "plt.scatter(y_test_nn, y_hat_nn)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_hat')\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.scatter(y_test, y_hat_base)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_hat baseline')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot some covariates \n",
    "plt.scatter(X_train.temp, y_train)\n",
    "plt.xlabel('Temp')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.scatter(X_train.humidity, y_train)\n",
    "plt.xlabel('Humidity')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.scatter(X_train.vpd, y_train)\n",
    "plt.xlabel('VPD')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot Jim wanted to see\n",
    "for year in xrange(2010,2017):\n",
    "    annual_fires = global_df[global_df.year == year]\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(12,10))\n",
    "    ax1 = plt.subplot(511)\n",
    "    plt.plot(annual_fires.dayofyear, annual_fires.n_det)\n",
    "    plt.title('Number of detections')\n",
    "\n",
    "    ax2 = plt.subplot(512, sharex=ax1)\n",
    "    plt.plot(annual_fires.dayofyear, annual_fires.n_det != 0, 'rs')\n",
    "    plt.title('Non-zero detection days')\n",
    "\n",
    "    ax3 = plt.subplot(513, sharex=ax1)\n",
    "    plt.plot(annual_fires.dayofyear, annual_fires.temp)\n",
    "    plt.title('Temperature')\n",
    "\n",
    "    ax4 = plt.subplot(514, sharex=ax1)\n",
    "    plt.plot(annual_fires.dayofyear, annual_fires.humidity)\n",
    "    plt.title('Humidity')\n",
    "\n",
    "    ax5 = plt.subplot(515)\n",
    "    plt.plot(annual_fires.dayofyear, annual_fires.vpd)\n",
    "    plt.title('VPD')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('pics/covar_subplot_%d.png' % year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.daymonth import day2monthday\n",
    "print day2monthday(242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot counts on top of each other for each year\n",
    "col_arr = ['r-', 'r--', 'b-', 'b--', 'y-', 'y--', 'k-', 'k--', 'g-']\n",
    "for i,year in enumerate(xrange(2010, 2017)):\n",
    "    annual_fires = global_df[global_df.year == year]\n",
    "    plt.plot(annual_fires.dayofyear, annual_fires.n_det, col_arr[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"%d fires\" % np.sum(global_df.n_det)\n",
    "print \"%d before 134, %d after 242\" % (np.sum(global_df[global_df.dayofyear<134].n_det), np.sum(global_df[global_df.dayofyear>242].n_det))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_df = global_df[(global_df.dayofyear >= 134) & (global_df.dayofyear <= 242)]\n",
    "X_train, y_train, X_test, y_test, y_hat_base = train_test_split(summer_df, feat_cols=['n_det', 'temp', 'vpd', 'humidity'], normalize_feats=False)\n",
    "print \"Shapes: \" + str([X_train.shape, y_train.shape, X_test.shape, y_test.shape])\n",
    "glm = sm.GLM(y_train, X_train, family=sm.genmod.families.family.Poisson(), missing='drop')\n",
    "glm_res = glm.fit()\n",
    "y_hat = glm_res.predict(X_test)\n",
    "print \"MSE model full: \" + str(evaluate_glm(y_test, y_hat))\n",
    "print \"MSE base: \" + str(evaluate_glm(y_test, y_hat_base))\n",
    "print \"MSE zeros: \" + str(evaluate_glm(y_test, np.zeros(len(y_test))))\n",
    "plt.scatter(X_train.temp, y_train)\n",
    "plt.xlabel('Temp')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.scatter(X_train.humidity, y_train)\n",
    "plt.xlabel('Humidity')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.scatter(X_train.vpd, y_train)\n",
    "plt.xlabel('VPD')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_delays = 7\n",
    "auto_arr = np.zeros(n_delays)\n",
    "det_arr = np.array(summer_df[summer_df.year==2014].n_det)\n",
    "for delay in xrange(n_delays):\n",
    "    auto_arr[delay] = np.corrcoef(np.array([det_arr[0:len(det_arr)-delay], det_arr[delay:]]))[0,1]\n",
    "plt.plot(auto_arr, 'rs')\n",
    "plt.title('Autoregressive coefs normal')\n",
    "plt.show()\n",
    "\n",
    "auto_arr = np.zeros(n_delays)\n",
    "det_arr = np.array(summer_df[summer_df.year==2014].n_det)\n",
    "for delay in xrange(n_delays):\n",
    "    auto_arr[delay] = np.corrcoef(np.array([np.log(det_arr[0:len(det_arr)-delay]+1), np.log(det_arr[delay:]+1)]))[0,1]\n",
    "plt.plot(auto_arr, 'rs')\n",
    "plt.title('Autoregressive coefs log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_dates = pr.get_regression_df(summer_df, covar_cols=['temp', 'vpd'], log_counts=True, autocorr_window=5)\n",
    "X_train, y_train, y_dates_train, X_test, y_test, y_dates_test = pr.train_test_split(X,y,y_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_res = pr.get_glm(X_train, y_train)\n",
    "glm_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = glm_res.predict(X_test)\n",
    "print \"MSE model (log): \" + str(pr.evaluate_glm(y_test, y_hat, log=True))\n",
    "print \"MSE base (log): \" + str(pr.evaluate_glm(y_test, np.exp(X_test.loc[:,'n_det']), log=True))\n",
    "print \"MSE zeros (log): \" + str(pr.evaluate_glm(y_test, np.zeros(len(y_test)), log=True))\n",
    "nzs = y_test != 0\n",
    "print \"MSE model (nz): \" + str(pr.evaluate_glm(y_test[nzs], y_hat[nzs]))\n",
    "print \"MSE base (nz): \" + str(pr.evaluate_glm(y_test[nzs], np.exp(X_test.loc[:,'n_det'])[nzs]))\n",
    "print \"MSE zeros (nz): \" + str(pr.evaluate_glm(y_test[nzs], np.zeros(np.sum(nzs))))\n",
    "plt.plot(np.log(y_test+1), np.log(y_hat+1), 'r+')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_hat')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test - y_hat, 'r+')\n",
    "plt.title(\"residuals\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.log(y_test+1), X_test.loc[:,'n_det'], 'r+')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_base')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(pr)\n",
    "X1, y1, y1_dates = pr.get_regression_df(summer_df, covar_cols=['temp', 'vpd'], normalize=[1,1], log_counts=True, autocorr_window=5)\n",
    "X2, y2, y2_dates = pr.get_regression_df(summer_df, covar_cols=['vpd'], normalize=[1,1], log_counts=False, autocorr_window=5)\n",
    "X3, y3, y3_dates = pr.get_regression_df(summer_df, covar_cols=[], normalize=[], log_counts=True, autocorr_window=1)\n",
    "X4, y4, y4_dates = pr.get_regression_df(summer_df, covar_cols=['temp', 'vpd'], normalize=[1,1], log_counts=False, autocorr_window=1)\n",
    "X1_train, y1_train, X1_test, y1_test = pr.train_test_split(X,y)\n",
    "idx = np.concatenate((X1_train.index, X1_test.index))\n",
    "X2_train, y2_train, X2_test, y2_test = pr.train_test_split(X2,y2,idx=idx)\n",
    "X3_train, y3_train, X3_test, y3_test = pr.train_test_split(X3,y3,idx=idx)\n",
    "X4_train, y4_train, X4_test, y4_test = pr.train_test_split(X4,y4,idx=idx)\n",
    "glm_res1 = pr.get_glm(X1_train, y1_train)\n",
    "glm_res2 = pr.get_glm(X2_train, y2_train)\n",
    "glm_res3 = pr.get_glm(X3_train, y3_train)\n",
    "glm_res4 = pr.get_glm(X4_train, y4_train)\n",
    "y1_hat = glm_res1.predict(X1_test)\n",
    "y2_hat = glm_res2.predict(X2_test)\n",
    "y3_hat = glm_res3.predict(X3_test)\n",
    "y4_hat = glm_res4.predict(X4_test)\n",
    "print \"MSE model1: \" + str(pr.evaluate_glm(y1_test, y1_hat))\n",
    "print \"MSE model2: \" + str(pr.evaluate_glm(y1_test, y2_hat))\n",
    "print \"MSE model3: \" + str(pr.evaluate_glm(y1_test, y3_hat))\n",
    "print \"MSE model4: \" + str(pr.evaluate_glm(y1_test, y4_hat))\n",
    "print \"MSE base (log): \" + str(pr.evaluate_glm(y1_test, X3_test.loc[:,'n_det']))\n",
    "print \"MSE base (not log): \" + str(pr.evaluate_glm(y1_test, np.exp(X3_test.loc[:,'n_det'])))\n",
    "print \"MSE zeros: \" + str(pr.evaluate_glm(y1_test, np.zeros(len(y1_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "glm = smf.glm('n_det ~ normvpd', data=X1, family=sm.genmod.families.family.Poisson())\n",
    "res = glm.fit()\n",
    "res.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bro in 'bro':\n",
    "    print bro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"yolo %d\" % 4,\n",
    "print \"swag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
