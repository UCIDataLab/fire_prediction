{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import cPickle\n",
    "import os\n",
    "import matplotlib\n",
    "os.chdir('/Users/zbutler/research/fire_prediction')\n",
    "from data import data\n",
    "import prediction.cluster_regression as cr\n",
    "from prediction.cluster_regression import ClusterRegression\n",
    "from metrics.evaluation import evaluate_glm, cross_validation_evaluation\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_feat_df = data.load_clust_feat_df(clust_thresh=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics for zero padding\n",
    "import metrics.evaluation as ev\n",
    "reload(ev)\n",
    "reload(cr)\n",
    "mets_baseline = dict()\n",
    "mets_mem = dict()\n",
    "mets_temphum = dict()\n",
    "mets_weather = dict()\n",
    "mets = (\"MSE\", \"RobustMSE\", \"MeanAbsErr\")\n",
    "\n",
    "cdf_with_stuff = cr.add_autoreg_and_n_det(clust_feat_df.copy(), autoreg_cols=1, t_k_max=6, zero_padding=True)\n",
    "print list(cdf_with_stuff.iloc[0:10][\"t_k_4\"])\n",
    "for t_k in range(5,-1,-1):\n",
    "    y_t_k_base = cdf_with_stuff[\"t_k_%d\" % t_k]\n",
    "    y_hat_t_k_base = cdf_with_stuff[\"autoreg_1\"]\n",
    "    my_mets = []\n",
    "    for met in mets:\n",
    "        my_mets.append(evaluate_glm(y_t_k_base, y_hat_t_k_base, metric=met))\n",
    "    mets_baseline[t_k] = my_mets\n",
    "    \n",
    "    mets_mem[t_k] = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[], zero_padding=True, return_arrs=False)\n",
    "    mets_temphum[t_k] = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\"], zero_padding=True, return_arrs=False)\n",
    "    mets_weather[t_k] = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\",\"wind\",\"rain_del_2\"], zero_padding=True, return_arrs=False)\n",
    "    print \"done with t_k %d\" % t_k\n",
    "print mets_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t_k = 6\n",
    "t_k_arr = range(n_t_k)\n",
    "for i,met in enumerate(mets):\n",
    "    base_arr = np.array(map(lambda x: mets_baseline[x][i], t_k_arr))\n",
    "    mem_arr = np.array(map(lambda x: mets_mem[x][i], t_k_arr))\n",
    "    temphum_arr = np.array(map(lambda x: mets_temphum[x][i], t_k_arr))\n",
    "    weather_arr = np.array(map(lambda x: mets_weather[x][i], t_k_arr))\n",
    "    \n",
    "    plt.plot(t_k_arr, base_arr, \"k--\", label=\"Baseline\")\n",
    "    plt.plot(t_k_arr, mem_arr, \"g--\", label=\"Memory\")\n",
    "    plt.plot(t_k_arr, temphum_arr, \"r--\", label=\"Temp/hum\")\n",
    "    plt.plot(t_k_arr, weather_arr, \"b--\", label=\"Weather\")\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(\"pics/t_k_zero_padding_%s.png\" % met)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics for nan padding\n",
    "import metrics.evaluation as ev\n",
    "reload(ev)\n",
    "reload(cr)\n",
    "mets_baseline = dict()\n",
    "mets_mem = dict()\n",
    "mets_temphum = dict()\n",
    "mets_weather = dict()\n",
    "mets = (\"MSE\", \"RobustMSE\", \"MeanAbsErr\")\n",
    "n_ex = []\n",
    "\n",
    "print 'yolo'\n",
    "#cdf_with_stuff = cr.add_autoreg_and_n_det(clust_feat_df.copy(), autoreg_cols=1, t_k_max=6, zero_padding=False)\n",
    "print list(cdf_with_stuff.iloc[0:10][\"t_k_4\"])\n",
    "for t_k in range(5,-1,-1):\n",
    "    y_t_k_base = cdf_with_stuff[\"t_k_%d\" % t_k]\n",
    "    y_hat_t_k_base = cdf_with_stuff[\"autoreg_1\"]\n",
    "    my_mets = []\n",
    "    for met in mets:\n",
    "        my_mets.append(ev.evaluate_glm(y_t_k_base, y_hat_t_k_base, metric=met))\n",
    "    mets_baseline[t_k] = my_mets\n",
    "    \n",
    "    mets_mem[t_k],y,y_hat = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[], zero_padding=False, return_arrs=True)\n",
    "    mets_temphum[t_k],y,y_hat = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\"], zero_padding=False, return_arrs=True)\n",
    "    mets_weather[t_k],y,y_hat = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\",\"wind\",\"rain_del_2\"], zero_padding=False, return_arrs=True)\n",
    "    \n",
    "    n_ex.append(np.sum(~np.isnan(y_t_k_base)))\n",
    "    print \"done with t_k %d\" % t_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t_k = 6\n",
    "t_k_arr = range(n_t_k)\n",
    "print mets_baseline\n",
    "plt.plot(t_k_arr, n_ex[::-1], 'r--')\n",
    "plt.xlabel(\"t_k\")\n",
    "plt.ylabel(\"Number of training examples\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "for i,met in enumerate(mets):\n",
    "    base_arr = np.array(map(lambda x: mets_baseline[x][i], t_k_arr))\n",
    "    mem_arr = np.array(map(lambda x: mets_mem[x][i], t_k_arr))\n",
    "    temphum_arr = np.array(map(lambda x: mets_temphum[x][i], t_k_arr))\n",
    "    weather_arr = np.array(map(lambda x: mets_weather[x][i], t_k_arr))\n",
    "    \n",
    "    plt.plot(t_k_arr, base_arr, \"k--\", label=\"Baseline\")\n",
    "    plt.plot(t_k_arr, mem_arr, \"g--\", label=\"Memory\")\n",
    "    plt.plot(t_k_arr, temphum_arr, \"r--\", label=\"Temp/hum\")\n",
    "    plt.plot(t_k_arr, weather_arr, \"b--\", label=\"Weather\")\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(\"pics/t_k_zero_padding_%s.png\" % met)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do it again but don't be a moron\n",
    "# Get metrics for zero padding\n",
    "import metrics.evaluation as ev\n",
    "reload(ev)\n",
    "reload(cr)\n",
    "mets_baseline = dict()\n",
    "mets_mem = dict()\n",
    "mets_temphum = dict()\n",
    "mets_weather = dict()\n",
    "mets = (\"MSE\", \"RobustMSE\", \"MeanAbsErr\")\n",
    "\n",
    "cdf_with_stuff = cr.add_autoreg_and_n_det(clust_feat_df.copy(), autoreg_cols=10, t_k_max=0, zero_padding=False)\n",
    "for t_k in range(5,-1,-1):\n",
    "    y_t_k_base = cdf_with_stuff['n_det']\n",
    "    y_hat_t_k_base = np.exp(cdf_with_stuff[\"autoreg_%d\" % (1 + t_k)]) - 1\n",
    "    my_mets = []\n",
    "    for met in mets:\n",
    "        my_mets.append(evaluate_glm(y_t_k_base, y_hat_t_k_base, metric=met))\n",
    "    mets_baseline[t_k] = my_mets\n",
    "    \n",
    "    mets_mem[t_k] = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[], zero_padding=True, return_arrs=False)\n",
    "    mets_temphum[t_k] = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\"], zero_padding=True, return_arrs=False)\n",
    "    mets_weather[t_k] = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\",\"wind\",\"rain_del_2\"], zero_padding=True, return_arrs=False)\n",
    "    print \"done with t_k %d\" % t_k\n",
    "print mets_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t_k = 6\n",
    "t_k_arr = range(n_t_k)\n",
    "print mets_baseline\n",
    "\n",
    "for i,met in enumerate(mets):\n",
    "    base_arr = np.array(map(lambda x: mets_baseline[x][i], t_k_arr))\n",
    "    mem_arr = np.array(map(lambda x: mets_mem[x][i], t_k_arr))\n",
    "    temphum_arr = np.array(map(lambda x: mets_temphum[x][i], t_k_arr))\n",
    "    weather_arr = np.array(map(lambda x: mets_weather[x][i], t_k_arr))\n",
    "    \n",
    "    plt.plot(t_k_arr, base_arr, \"k--\", label=\"Baseline\")\n",
    "    plt.plot(t_k_arr, mem_arr, \"g--\", label=\"Memory\")\n",
    "    plt.plot(t_k_arr, temphum_arr, \"r--\", label=\"Temp/hum\")\n",
    "    plt.plot(t_k_arr, weather_arr, \"b--\", label=\"Weather\")\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.savefig(\"pics/t_k_zero_padding_%s.png\" % met)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_nanners(df, weather_vars):\n",
    "    for cov in weather_vars:\n",
    "        nanners = df[np.isnan(df[cov])]\n",
    "        for name in nanners.index:\n",
    "            clust = nanners.loc[name].cluster\n",
    "            dayofyear = nanners.loc[name].dayofyear\n",
    "            next_offset_to_try = -1\n",
    "            while 1:\n",
    "                # If offset is getting too far away, just replace with mean across all time\n",
    "                if abs(next_offset_to_try) > 5:\n",
    "                    df.set_value(name, cov, np.mean(df[cov]))\n",
    "                    break\n",
    "                pot_val = df[(df.dayofyear==(dayofyear+next_offset_to_try)) & (df.cluster==clust)][cov]\n",
    "                if not len(pot_val) or np.isnan(float(pot_val)):\n",
    "                    if next_offset_to_try < 0:\n",
    "                        next_offset_to_try = - next_offset_to_try\n",
    "                    else:\n",
    "                        next_offset_to_try = - (next_offset_to_try + 1)\n",
    "                else:\n",
    "                    df.set_value(name, cov, float(pot_val))\n",
    "                    break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do it again but don't be a moron\n",
    "# Get metrics for zero padding\n",
    "import metrics.evaluation as ev\n",
    "reload(ev)\n",
    "reload(cr)\n",
    "mets_baseline = dict()\n",
    "mets_mem = dict()\n",
    "mets_temphum = dict()\n",
    "mets_weather = dict()\n",
    "mets_only_weather = dict()\n",
    "mets = (\"MSE\", \"RobustMSE\", \"MeanAbsErr\")\n",
    "print \"hi\"\n",
    "#cdf_with_stuff = cr.add_autoreg_and_n_det(clust_feat_df.copy(), autoreg_cols=10, t_k_max=0, zero_padding=False)\n",
    "#cdf_with_stuff = kill_nanners(cdf_with_stuff.copy(), [\"temp\", \"humidity\", \"wind\", \"rain_del_2\"])\n",
    "max_t_k = 4\n",
    "\n",
    "for t_k in range(max_t_k,-1,-1):\n",
    "    legit_series = pd.Series(index=cdf_with_stuff.index)\n",
    "    for clust in cdf_with_stuff.cluster.unique():\n",
    "        clust_df = cdf_with_stuff[cdf_with_stuff.cluster==clust]\n",
    "        legit_day = np.min(clust_df.dayofyear) + t_k\n",
    "        legit_series[clust_df[clust_df.dayofyear >= legit_day].index] = 1\n",
    "    y_t_k_base = cdf_with_stuff[legit_series == 1]['n_det']\n",
    "    y_hat_t_k_base = np.exp(cdf_with_stuff[legit_series == 1][\"autoreg_%d\" % (1 + t_k)]) - 1\n",
    "    my_mets = []\n",
    "    for met in mets:\n",
    "        my_mets.append(evaluate_glm(y_t_k_base, y_hat_t_k_base, metric=met))\n",
    "    mets_baseline[t_k] = my_mets\n",
    "    \n",
    "    mets_mem[t_k] = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series)\n",
    "    mets_temphum[t_k] = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\"], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series)\n",
    "    mets_weather[t_k] = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=t_k, weather_vars=[\"temp\",\"humidity\",\"wind\",\"rain_del_2\"], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series)\n",
    "    mets_only_weather[t_k]= ev.cross_validation_evaluation(cdf_with_stuff, autoreg=0, t_k=t_k, weather_vars=[\"temp\",\"humidity\",\"wind\",\"rain_del_2\"], zero_padding=False, return_arrs=False, max_t_k=t_k, legit_series=legit_series)\n",
    "    print \"done with t_k %d\" % t_k\n",
    "print mets_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t_k = 5\n",
    "t_k_arr = np.arange(n_t_k)\n",
    "mets = [\"MeanAbsErr\"]\n",
    "i = 2\n",
    "for met in mets:\n",
    "    base_arr = np.array(map(lambda x: mets_baseline[x][i], t_k_arr))\n",
    "    mem_arr = np.array(map(lambda x: mets_mem[x][i], t_k_arr))\n",
    "    temphum_arr = np.array(map(lambda x: mets_temphum[x][i], t_k_arr))\n",
    "    weather_arr = np.array(map(lambda x: mets_weather[x][i], t_k_arr))\n",
    "    only_weather_arr = np.array(map(lambda x: mets_only_weather[x][i], t_k_arr))\n",
    "    \n",
    "    plt.plot(t_k_arr+1, base_arr, \"kv--\", label=\"Baseline\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, mem_arr, \"gs--\", label=\"Autoregression\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, temphum_arr, \"r^--\", label=\"Temp/hum\", linewidth=2)\n",
    "    plt.plot(t_k_arr+1, weather_arr, \"bo--\", label=\"All weather\", linewidth=2)\n",
    "    #plt.plot(t_k_arr+1, only_weather_arr, \"m--\", label=\"Only weather\")\n",
    "#plt.axhline(y=mets_only_weather[i], color=\"m\", label=\"Weather only\")\n",
    "    \n",
    "    matplotlib.rcParams.update({'font.size': 14})\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlabel(\"Day of forecast (k)\")\n",
    "    plt.xticks(t_k_arr+1)\n",
    "    plt.ylabel(\"Mean absolute error (2007-2016)\")\n",
    "    plt.savefig(\"pics/mae.png\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for met in mets:\n",
    "    base_arr = np.array(map(lambda x: mets_baseline[x][i], t_k_arr))\n",
    "    mem_arr = np.array(map(lambda x: mets_mem[x][i], t_k_arr))\n",
    "    temphum_arr = np.array(map(lambda x: mets_temphum[x][i], t_k_arr))\n",
    "    weather_arr = np.array(map(lambda x: mets_weather[x][i], t_k_arr))\n",
    "    only_weather_arr = np.array(map(lambda x: mets_only_weather[x][i], t_k_arr))\n",
    "    \n",
    "    plt.plot(t_k_arr+1, base_arr / base_arr, \"k--\", label=\"Baseline\")\n",
    "    plt.plot(t_k_arr+1, mem_arr / base_arr, \"g--\", label=\"Memory\")\n",
    "    plt.plot(t_k_arr+1, temphum_arr / base_arr, \"r--\", label=\"Temp/hum\")\n",
    "    plt.plot(t_k_arr+1, weather_arr / base_arr, \"b--\", label=\"Weather\")\n",
    "    plt.plot(t_k_arr+1, only_weather_arr / base_arr, \"m--\", label=\"Weather only\")\n",
    "    \n",
    "    lgd = plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlabel(\"Days into the future we are predicting\")\n",
    "    plt.xticks(t_k_arr+1)\n",
    "    plt.ylabel(\"Mean absolute error (relative to baseline)\")\n",
    "    plt.savefig(\"pics/mae_rel_only_weather.png\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging, what's up with MeanAbsErr?\n",
    "# First, let's train the zero-padded models on all but 2013 and see what we get for\n",
    "y_t_k_base = cdf_with_stuff['n_det']\n",
    "y_hat_t_k_base = np.exp(cdf_with_stuff[\"autoreg_%d\" % 1]) - 1\n",
    "my_mets = []\n",
    "for met in mets:\n",
    "    my_mets.append(evaluate_glm(y_t_k_base, y_hat_t_k_base, metric=met))\n",
    "mets_mem_z,y_mem,y_hat_mem = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=0, weather_vars=[], zero_padding=False, return_arrs=True)\n",
    "mets_temphum_z,y_temp,y_hat_temp = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=0, weather_vars=[\"temp\",\"humidity\"], zero_padding=False, return_arrs=True)\n",
    "mets_weather_z,y_weather,y_hat_weather = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=0, weather_vars=[\"temp\",\"humidity\",\"wind\",\"rain_del_2\"], zero_padding=False, return_arrs=True)\n",
    "print \"baseline_mets: \" + str(my_mets)\n",
    "plt.scatter(y_t_k_base,y_hat_t_k_base)\n",
    "plt.xlabel(\"y\")\n",
    "plt.ylabel(\"y_hat\")\n",
    "plt.title(\"Baseline\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print \"memory_mets: \" + str(mets_mem_z)\n",
    "plt.scatter(y_mem,y_hat_mem)\n",
    "plt.xlabel(\"y\")\n",
    "plt.ylabel(\"y_hat\")\n",
    "plt.title(\"Memory\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print \"temp/hum_mets: \" + str(mets_temphum_z)\n",
    "plt.scatter(y_temp,y_hat_temp)\n",
    "plt.xlabel(\"y\")\n",
    "plt.ylabel(\"y_hat\")\n",
    "plt.title(\"Temp/hum\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print \"weather_mets: \" + str(mets_weather_z)\n",
    "plt.scatter(y_weather,y_hat_weather)\n",
    "plt.xlabel(\"y\")\n",
    "plt.ylabel(\"y_hat\")\n",
    "plt.title(\"Weather\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, how is memory doing so shittily compared to the baseline wrt mean abs error?\n",
    "plt.scatter(np.abs(y_hat_mem - y_mem), np.abs(y_hat_t_k_base - y_mem))\n",
    "plt.title(\"mean abs err scatter plot\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter((y_hat_mem - y_mem)**2, (y_hat_t_k_base - y_mem)**2)\n",
    "plt.title(\"mse scatter plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ev)\n",
    "mets_mem_z,y_mem,y_hat_mem = ev.cross_validation_evaluation(cdf_with_stuff, autoreg=1, t_k=0, weather_vars=[], zero_padding=False, return_arrs=True, print_covars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(clust_feat_df.n_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(legit_series == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from prediction.cluster_regression import add_autoreg_and_n_det\n",
    "#cdf = add_autoreg_and_n_det(clust_feat_df, 1,0)\n",
    "plt.scatter(np.exp(cdf.autoreg_1)-1, cdf.n_det)\n",
    "plt.axhline(y=0.0, color='k')\n",
    "plt.axvline(x=0.0, color='k')\n",
    "plt.xlabel(\"Counts at time t\")\n",
    "plt.ylabel(\"Counts at time t+1\")\n",
    "plt.show()\n",
    "\n",
    "print \"zero days: %d of %d\" % (len(cdf[cdf.n_det == 0]), len(cdf))\n",
    "\n",
    "cut_pts = [0, 1, 10, 100, 1000]\n",
    "for i in xrange(len(cut_pts)-1):\n",
    "    my_pts = cdf[(np.exp(cdf.autoreg_1)-1 >= cut_pts[i]) & (np.exp(cdf.autoreg_1)-1 < cut_pts[i+1])]\n",
    "    print \"For clusters and days with [%d,%d) detections (%d such days), we have on average %f detections tomorrow\" % (cut_pts[i], cut_pts[i+1], len(my_pts), np.mean(my_pts.n_det))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
