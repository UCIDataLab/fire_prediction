{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import cPickle\n",
    "import os\n",
    "os.chdir('/Users/zbutler/research/fire_prediction')\n",
    "from data import data\n",
    "import prediction.cluster_regression\n",
    "reload(prediction.cluster_regression)\n",
    "from prediction.cluster_regression import ClusterRegression\n",
    "from prediction.poisson_regression import evaluate_glm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(data)\n",
    "clust_feat_df = data.load_clust_feat_df(clust_thresh=5)\n",
    "cr = ClusterRegression(clust_feat_df, 5, 'unused', 5)\n",
    "def all_except_year(year, rng=(2007,2016)):\n",
    "    return [x for x in range(rng[0],rng[1]+1) if x!=year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check out autocorrelation on the whole data to figure out how much we want to use\n",
    "print \"Autoreg\\tIntercept\\tCoef 1\\tCoef 2\\tCoef 3\\tCoef4\\tCoef 5\"\n",
    "for n_auto in xrange(1,6):\n",
    "    ft = cr.fit(range(2007,2017), n_auto, weather_vars=[])\n",
    "    print \"%d\\t%f\\t\" % (n_auto, ft.params[\"Intercept\"]),\n",
    "    for coef in xrange(1,n_auto+1):\n",
    "        print \"%f\\t\" % ft.params[\"autoreg_%d\" % coef],\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do coefficients vary depending on the testing data? We'll try holding out each year separately\n",
    "ft = cr.fit(2010, 1, weather_vars=['temp','humidity','wind','rain'], standardize_covs=True)\n",
    "param_names = ft.params.keys()\n",
    "print \"Covariates with rain (standardized)\"\n",
    "print \"HO Year\\t\",\n",
    "for param in param_names:\n",
    "    print param + \"\\t\",\n",
    "print \"\"\n",
    "\n",
    "for ho_year in xrange(2007, 2017):\n",
    "    ft = cr.fit(all_except_year(ho_year), 1, weather_vars=['temp','humidity','wind','rain'], standardize_covs=True)\n",
    "    print str(ho_year) + \"\\t\",\n",
    "    for param in param_names:\n",
    "        print \"%.3f\\t\\t\" % ft.params[param],\n",
    "    print \"\"\n",
    "    \n",
    "print \"\\n\"\n",
    "\n",
    "ft = cr.fit(2010, 1, weather_vars=['temp','humidity','wind','rain_del_2'], standardize_covs=True)\n",
    "param_names = ft.params.keys()\n",
    "print \"Covariates with lagged rain (standardized)\"\n",
    "print \"HO Year\\t\",\n",
    "for param in param_names:\n",
    "    print param + \"\\t\",\n",
    "print \"\"\n",
    "\n",
    "for ho_year in xrange(2007, 2017):\n",
    "    ft = cr.fit(all_except_year(ho_year), 1, weather_vars=['temp','humidity','wind','rain_del_2'], standardize_covs=True)\n",
    "    print str(ho_year) + \"\\t\",\n",
    "    for param in param_names:\n",
    "        print \"%.3f\\t\\t\" % ft.params[param],\n",
    "    print \"\"\n",
    "\n",
    "print \"\\n\"\n",
    "ft = cr.fit(2010, 1, weather_vars=['temp','humidity','wind','rain_del_2'], standardize_covs=False)\n",
    "param_names = ft.params.keys()\n",
    "print \"Covariates with lagged rain (unstandardized)\"\n",
    "print \"HO Year\\t\",\n",
    "for param in param_names:\n",
    "    print param + \"\\t\",\n",
    "print \"\"\n",
    "for ho_year in xrange(2007, 2017):\n",
    "    ft = cr.fit(all_except_year(ho_year), 1, weather_vars=['temp','humidity','wind','rain_del_2'], standardize_covs=False)\n",
    "    print str(ho_year) + \"\\t\",\n",
    "    for param in param_names:\n",
    "        print \"%.3f\\t\\t\" % ft.params[param],\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much lag or whatever do the weather covariates \"want\"?\n",
    "lag_arr_dict = dict()\n",
    "w_vars = [\"temp\", \"humidity\", \"wind\", \"rain\"]\n",
    "for var in w_vars:\n",
    "    lag_arr_dict[var] = []\n",
    "    \n",
    "for t in xrange(-4, 4):\n",
    "    series_dict = dict()\n",
    "    for var in w_vars:\n",
    "        series_dict[var] = dict()\n",
    "    for clust in clust_feat_df.cluster.unique():\n",
    "        clust_df = clust_feat_df[clust_feat_df.cluster == clust]\n",
    "        days = clust_df.dayofyear.unique()\n",
    "        for day in days:\n",
    "            day_row = clust_df[clust_df.dayofyear==day]\n",
    "            name = day_row.iloc[0].name\n",
    "            delayed_weather_day = day - t\n",
    "            for var in w_vars:\n",
    "                if delayed_weather_day in days:\n",
    "                    w_val = clust_df[clust_df.dayofyear==delayed_weather_day].iloc[0][var]\n",
    "                    if np.isnan(w_val):\n",
    "                        series_dict[var][name] = 0.\n",
    "                    else:\n",
    "                        series_dict[var][name] = w_val\n",
    "                else:\n",
    "                    series_dict[var][name] = 0.\n",
    "    for var in w_vars:\n",
    "        lag_arr_dict[var].append(pd.Series(series_dict[var]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,12))\n",
    "for i,var in enumerate(w_vars):\n",
    "    ax = plt.subplot(221 + i)\n",
    "    corrs = map(lambda x: pearsonr(clust_feat_df.n_det, x.loc[clust_feat_df.index]), lag_arr_dict[var])\n",
    "    plt.plot(range(-4,4), map(lambda x: x[0], corrs), 'b--')\n",
    "    plt.axvline(x=0, color='r', linestyle='--')\n",
    "    plt.xlabel(\"Weather delay\")\n",
    "    plt.ylabel(\"Pearson correlation\")\n",
    "    plt.title(var)\n",
    "\n",
    "plt.savefig(\"pics/weather_delay_fig.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make models that hold out every year\n",
    "memory_mods = dict()\n",
    "temphum_mods = dict()\n",
    "weather_mods = dict()\n",
    "only_weather_mods = dict()\n",
    "weather_del_mods = dict()\n",
    "for ho_year in xrange(2007, 2017):\n",
    "    memory_mods[ho_year] = cr.fit(all_except_year(ho_year), 1, weather_vars=[])\n",
    "    temphum_mods[ho_year] = cr.fit(all_except_year(ho_year), 1, weather_vars=[\"temp\", \"humidity\"], standardize_covs=False)\n",
    "    only_weather_mods[ho_year] = cr.fit(all_except_year(ho_year), 0, weather_vars=[\"temp\", \"humidity\", \"wind\", \"rain_del_2\"], standardize_covs=False)\n",
    "    weather_mods[ho_year] = cr.fit(all_except_year(ho_year), 1, weather_vars=[\"temp\", \"humidity\", \"wind\", \"rain\"], standardize_covs=False)\n",
    "    weather_del_mods[ho_year] = cr.fit(all_except_year(ho_year), 1, weather_vars=[\"temp\", \"humidity\", \"wind\", \"rain_del_2\"], standardize_covs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lin_comb(df, params):\n",
    "    lin_comb = np.zeros(len(df))\n",
    "    for param, val in params.iteritems():\n",
    "        if param == \"Intercept\":\n",
    "            lin_comb += val\n",
    "        else:\n",
    "            lin_comb += val * df[param]\n",
    "    lin_comb[np.isnan(lin_comb)] = np.mean(lin_comb)\n",
    "    return lin_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prediction.poisson_regression as pr\n",
    "reload(pr)\n",
    "from prediction.poisson_regression import evaluate_glm\n",
    "\n",
    "# Let's plot overall error for each error type for each of our 5 models\n",
    "n_occ = []\n",
    "for year in xrange(2007, 2017):\n",
    "    n_occ.append(len(clust_feat_df[clust_feat_df.year==year]))\n",
    "n_occ = np.array(n_occ)\n",
    "    \n",
    "metrics =[\"MSE\", \"RobustMSE\", \"MeanAbsErr\"]#, \"ll\"]\n",
    "for met in metrics:\n",
    "    print met\n",
    "    year_range = np.arange(2007, 2017)\n",
    "    baseline_met = np.zeros(len(year_range))\n",
    "    memory_met = np.zeros(len(year_range))\n",
    "    temphum_met = np.zeros(len(year_range))\n",
    "    weather_met = np.zeros(len(year_range))\n",
    "    weather_del_met = np.zeros(len(year_range))\n",
    "    \n",
    "    for i,year in enumerate(year_range):\n",
    "        test_df = clust_feat_df[clust_feat_df.year==year]\n",
    "        # Replace NaNs with value from nearest day we have data\n",
    "        weather_covs = [\"temp\", \"humidity\", \"wind\", \"rain\", \"rain_del_2\"]\n",
    "        for cov in weather_covs:\n",
    "            nanners = test_df[np.isnan(test_df[cov])]\n",
    "            for name in nanners.index:\n",
    "                clust = nanners.loc[name].cluster\n",
    "                dayofyear = nanners.loc[name].dayofyear\n",
    "                next_offset_to_try = -1\n",
    "                while 1:\n",
    "                    # If offset is getting too far away, just replace with mean across all time\n",
    "                    if abs(next_offset_to_try) > 5:\n",
    "                        test_df.set_value(name, cov, np.mean(test_df[cov]))\n",
    "                        break\n",
    "                    pot_val = test_df[(test_df.dayofyear==(dayofyear+next_offset_to_try)) & (test_df.cluster==clust)][cov]\n",
    "                    if not len(pot_val) or np.isnan(float(pot_val)):\n",
    "                        if next_offset_to_try < 0:\n",
    "                            next_offset_to_try = - next_offset_to_try\n",
    "                        else:\n",
    "                            next_offset_to_try = - (next_offset_to_try + 1)\n",
    "                    else:\n",
    "                        test_df.set_value(name, cov, float(pot_val))\n",
    "                        break\n",
    "\n",
    "        if met == \"ll\":\n",
    "            memory_lins = get_lin_comb(test_df, memory_mods[year].params)\n",
    "            memory_met[i] = evaluate_glm(test_df.n_det, test_df.autoreg_1, lins=memory_lins, metric=met)\n",
    "            temphum_lins = get_lin_comb(test_df, temphum_mods[year].params)\n",
    "            temphum_met[i] = evaluate_glm(test_df.n_det, test_df.autoreg_1, lins=temphum_lins, metric=met)\n",
    "            weather_lins = get_lin_comb(test_df, weather_mods[year].params)\n",
    "            weather_met[i] = evaluate_glm(test_df.n_det, test_df.autoreg_1, lins=weather_lins, metric=met)\n",
    "            weather_del_lins = get_lin_comb(test_df, weather_del_mods[year].params)\n",
    "            weather_del_met[i] = evaluate_glm(test_df.n_det, test_df.autoreg_1, lins=weather_del_lins, metric=met)\n",
    "        else:\n",
    "            n_out = int(.01 * len(test_df))\n",
    "            baseline_met[i] = evaluate_glm(test_df.n_det, np.exp(test_df.autoreg_1)-1, metric=met, toss_outliers=n_out)\n",
    "            memory_met[i] = evaluate_glm(test_df.n_det, memory_mods[year].predict(test_df), metric=met, toss_outliers=n_out)\n",
    "            temphum_met[i] = evaluate_glm(test_df.n_det, temphum_mods[year].predict(test_df), metric=met, toss_outliers=n_out)\n",
    "            weather_met[i] = evaluate_glm(test_df.n_det, weather_mods[year].predict(test_df), metric=met, toss_outliers=n_out)\n",
    "            weather_del_met[i] = evaluate_glm(test_df.n_det, weather_del_mods[year].predict(test_df), metric=met, toss_outliers=n_out)\n",
    "\n",
    "    if met != \"ll\":\n",
    "        base = baseline_met\n",
    "        plt.plot(year_range, baseline_met / base, 'k--', label='Baseline')\n",
    "    else:\n",
    "        base = map(lambda w,x,y,z: min(w,x,y,z), memory_met, temphum_met, weather_met, weather_del_met)\n",
    "    plt.plot(year_range, memory_met/base, 'r--', label='Memory')\n",
    "    plt.plot(year_range, temphum_met/base, 'm--', label='Temp/Humidity')\n",
    "    plt.plot(year_range, weather_met/base, 'b--', label='Weather')\n",
    "    plt.plot(year_range, weather_del_met/base, 'g--', label='Weather (rain lag)')\n",
    "    plt.xlabel(\"Held-out Year\")\n",
    "    plt.ylabel(met)\n",
    "    plt.title(\"%s for cluster regression\" % met)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "    plt.savefig(\"pics/cluster_model_%s.png\" % met)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    if met != \"ll\":\n",
    "        print \"baseline overall: \" + str(np.dot(n_occ, baseline_met) / len(n_occ))\n",
    "    print \"memory overall: \" + str(np.dot(n_occ, memory_met) / len(n_occ))\n",
    "    print \"temphum overall: \" + str(np.dot(n_occ, temphum_met) / len(n_occ))\n",
    "    print \"weather overall: \" + str(np.dot(n_occ, weather_met) / len(n_occ))\n",
    "    print \"rain lag overall: \" + str(np.dot(n_occ, weather_del_met) / len(n_occ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2013\n",
    "clust = clust_feat_df[clust_feat_df.year==2013].cluster.unique()[0]\n",
    "clust_df = clust_feat_df[(clust_feat_df.year==year) & (clust_feat_df.cluster==clust)]\n",
    "print len(clust_df)\n",
    "ys = clust_df.n_det\n",
    "y_hats = np.exp(clust_df.autoreg_1)-1\n",
    "plt.plot(clust_df.dayofyear, ys, 'b--')\n",
    "plt.plot(clust_df.dayofyear, y_hats, 'r--')\n",
    "plt.title(\"baseline\")\n",
    "plt.show()\n",
    "y_hats = memory_mods[year].predict(clust_df)\n",
    "plt.plot(clust_df.dayofyear, ys, 'b--')\n",
    "plt.plot(clust_df.dayofyear, y_hats, 'r--')\n",
    "plt.title(\"memory\")\n",
    "plt.show()\n",
    "y_hats = temphum_mods[year].predict(clust_df)\n",
    "plt.plot(clust_df.dayofyear, ys, 'b--')\n",
    "plt.plot(clust_df.dayofyear, y_hats, 'r--')\n",
    "plt.title(\"Temp/Hum\")\n",
    "plt.show()\n",
    "y_hats = weather_mods[year].predict(clust_df)\n",
    "plt.plot(clust_df.dayofyear, ys, 'b--')\n",
    "plt.plot(clust_df.dayofyear, y_hats, 'r--')\n",
    "plt.title(\"weather\")\n",
    "plt.show()\n",
    "y_hats = weather_del_mods[year].predict(clust_df)\n",
    "plt.plot(clust_df.dayofyear, ys, 'b--')\n",
    "plt.plot(clust_df.dayofyear, y_hats, 'r--')\n",
    "plt.title(\"weather (rain lag)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_nans(test_df):\n",
    "    weather_covs = [\"temp\", \"humidity\", \"wind\", \"rain\", \"rain_del_2\"]\n",
    "    for cov in weather_covs:\n",
    "        nanners = test_df[np.isnan(test_df[cov])]\n",
    "        for name in nanners.index:\n",
    "            clust = nanners.loc[name].cluster\n",
    "            dayofyear = nanners.loc[name].dayofyear\n",
    "            next_offset_to_try = -1\n",
    "            while 1:\n",
    "                # If offset is getting too far away, just replace with mean across all time\n",
    "                if abs(next_offset_to_try) > 5:\n",
    "                    test_df.set_value(name, cov, np.mean(test_df[cov]))\n",
    "                    break\n",
    "                pot_val = test_df[(test_df.dayofyear==(dayofyear+next_offset_to_try)) & (test_df.cluster==clust)][cov]\n",
    "                if not len(pot_val) or np.isnan(float(pot_val)):\n",
    "                    if next_offset_to_try < 0:\n",
    "                        next_offset_to_try = - next_offset_to_try\n",
    "                    else:\n",
    "                        next_offset_to_try = - (next_offset_to_try + 1)\n",
    "                else:\n",
    "                    test_df.set_value(name, cov, float(pot_val))\n",
    "                    break\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r','g','b','k','c','m','y']\n",
    "for mod_type in ['baseline', 'memory', 'temphum', 'weather_del']:\n",
    "    for i,year in enumerate(xrange(2007, 2017)):\n",
    "        test_df = clust_feat_df[clust_feat_df.year==year]\n",
    "        test_df = kill_nans(test_df)\n",
    "        y = test_df.n_det\n",
    "        if mod_type == 'baseline':\n",
    "            y_hat = np.exp(test_df.autoreg_1)-1\n",
    "        elif mod_type == 'memory':\n",
    "            y_hat = memory_mods[year].predict(test_df)\n",
    "        elif mod_type == 'temphum':\n",
    "            y_hat = temphum_mods[year].predict(test_df)\n",
    "        elif mod_type == 'weather_del':\n",
    "            y_hat = weather_del_mods[year].predict(test_df)\n",
    "        color = colors[i % len(colors)]\n",
    "        if i < len(colors):\n",
    "            marker = 'o'\n",
    "        else:\n",
    "            marker = 's'\n",
    "        plt.plot(np.log(y+1), np.log(y_hat+1), color + marker, label=year)\n",
    "    plt.xlabel(\"y\")\n",
    "    plt.ylabel(\"y_hat\")\n",
    "    plt.title(mod_type)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r','g','b','k','c','m','y']\n",
    "for mod_type in ['baseline', 'memory', 'temphum', 'weather_del']:\n",
    "    for i,year in enumerate(xrange(2007, 2017)):\n",
    "        test_df = clust_feat_df[clust_feat_df.year==year]\n",
    "        test_df = kill_nans(test_df)\n",
    "        y = test_df.n_det\n",
    "        if mod_type == 'baseline':\n",
    "            y_hat = np.exp(test_df.autoreg_1)-1\n",
    "        elif mod_type == 'memory':\n",
    "            y_hat = memory_mods[year].predict(test_df)\n",
    "        elif mod_type == 'temphum':\n",
    "            y_hat = temphum_mods[year].predict(test_df)\n",
    "        elif mod_type == 'weather_del':\n",
    "            y_hat = weather_del_mods[year].predict(test_df)\n",
    "        color = colors[i % len(colors)]\n",
    "        if i < len(colors):\n",
    "            marker = 'o'\n",
    "        else:\n",
    "            marker = 's'\n",
    "        plt.plot(y, y_hat, color + marker, label=year)\n",
    "    plt.xlabel(\"y\")\n",
    "    plt.ylabel(\"y_hat\")\n",
    "    plt.title(mod_type)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.sum(np.isnan(clust_feat_df.rain))\n",
    "print len(clust_feat_df)\n",
    "for clust in clust_feat_df.cluster.unique():\n",
    "    if len(clust_feat_df[clust_feat_df.cluster==clust].year.unique()) != 1:\n",
    "        print \"oh no %d\" % clust\n",
    "print 'yay'\n",
    "clust_feat_df.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to make some data for Padhraic. Rows will be fire events, and i will have the following columns:\n",
    "* clust ID\n",
    "* clust ID of merger\n",
    "* dayofyear\n",
    "* day of cluster\n",
    "* year\n",
    "* lat\n",
    "* lon\n",
    "* y_t\n",
    "* y_t-1\n",
    "* weather\n",
    "* y_hat[memory]\n",
    "* y_hat[temphum]\n",
    "* y_hat[weather_no_autoreg]\n",
    "* y_hat[weather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/prediction_summary.csv\", \"w\") as fout:\n",
    "    fout.write(\"clustID,clustIDmerge,dayOfYear,dayOfClust,year,lat,lon,y_t,y_t-1,temp,humidity,wind,delRain,yhat_mem,yhat_temphum,yhat_onlyweather,yhat_all\\n\")\n",
    "    gtfo = 0\n",
    "    for clust in clust_feat_df.cluster.unique():\n",
    "        clust_df = clust_feat_df[clust_feat_df.cluster==clust]\n",
    "        alt_clust = clust_df.iloc[0].alt_cluster\n",
    "        if isinstance(alt_clust, tuple):\n",
    "            alt_clust = alt_clust[0]\n",
    "        else:\n",
    "            alt_clust = -1\n",
    "        year = clust_df.iloc[0].year\n",
    "        lat = clust_df.iloc[0].lat_centroid\n",
    "        lon = clust_df.iloc[0].lon_centroid\n",
    "        days = np.sort(clust_df.dayofyear.unique())\n",
    "        for i,day in enumerate(days):\n",
    "            fout.write(\"%d,%d,%d,%d,%d,%f,%f,\" % (int(clust), int(alt_clust), int(day), i, int(year), lat, lon))\n",
    "            row = clust_df[clust_df.dayofyear==day].iloc[0]\n",
    "            for var in ['temp','humidity','wind','rain_del_2']:\n",
    "                next_offset_to_try = -1\n",
    "                while np.isnan(row[var]):\n",
    "                    # If offset is getting too far away, just replace with mean across that day\n",
    "                    if abs(next_offset_to_try) > 5:\n",
    "                        row[var] = np.mean(clust_feat_df[(clust_feat_df.year==year) & (clust_feat_df.dayofyear==dayofyear)][var])\n",
    "                        if np.isnan(row[var]):   # If we still can't do that, replace with the mean for the past 2 weeks week\n",
    "                            row[var] = np.mean(clust_feat_df[(clust_feat_df.year==year) & (abs(clust_feat_df.dayofyear - dayofyear) < 7)][var])\n",
    "                        break\n",
    "                    #print \"boop: \" + str(clust_df[(clust_df.dayofyear==(dayofyear+next_offset_to_try))])\n",
    "                    pot_val = clust_df[(clust_df.dayofyear==(dayofyear+next_offset_to_try))][cov]\n",
    "                    if not len(pot_val) or np.isnan(float(pot_val)):\n",
    "                        if next_offset_to_try < 0:\n",
    "                            next_offset_to_try = - next_offset_to_try\n",
    "                        else:\n",
    "                            next_offset_to_try = - (next_offset_to_try + 1)\n",
    "                    else:\n",
    "                        row[var] = float(pot_val)\n",
    "                        break\n",
    "            try:\n",
    "                fout.write(\"%d,%d,%f,%f,%f,%f,\" % (row.n_det, np.exp(row.autoreg_1)-1, row.temp, row.humidity, row.wind, row.rain_del_2))\n",
    "                fout.write(\"%f,%f,%f,%f\\n\" % (memory_mods[year].predict(row)[0], temphum_mods[year].predict(row)[0], only_weather_mods[year].predict(row)[0], weather_del_mods[year].predict(row)[0]))\n",
    "            except IndexError:\n",
    "                print row\n",
    "                print next_offset_to_try\n",
    "                print clust_feat_df[(clust_feat_df.year==year) & (clust_feat_df.dayofyear==dayofyear)][var]\n",
    "                gtfo = 1\n",
    "                break\n",
    "        if gtfo:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(prediction.cluster_regression)\n",
    "from prediction.cluster_regression import ClusterRegression\n",
    "cr = ClusterRegression(clust_feat_df, 5, 'unused', 5)\n",
    "ft = cr.fit(range(2007,2017), 1, weather_vars=['temp','humidity','wind','rain_del_2'], standardize_covs=True)\n",
    "param_names = ft.params.keys()\n",
    "print \"Covariates with lagged rain (standardized)\"\n",
    "for param in param_names:\n",
    "    print param + \"\\t\",\n",
    "print \"\"\n",
    "\n",
    "for param in param_names:\n",
    "    print \"%.3f\\t\\t\" % ft.params[param],\n",
    "print \"\"\n",
    "print \"\\n\"\n",
    "\n",
    "ft = cr.fit(range(2007,2017), 1, weather_vars=['temp','humidity','wind','rain_del_2'], standardize_covs=False)\n",
    "param_names = ft.params.keys()\n",
    "print \"Covariates with lagged rain (unstandardized)\"\n",
    "for param in param_names:\n",
    "    print param + \"\\t\",\n",
    "print \"\"\n",
    "\n",
    "for param in param_names:\n",
    "    print \"%.3f\\t\\t\" % ft.params[param],\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr.clust_df.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
